{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone proposal by Mirko Salomon \n",
    "\n",
    "# BEVERAGE MACHINE CHURN PREDICTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ## [1) Introduction and preparation](#Introduction) \n",
    "\n",
    "    *   \n",
    "        #### Data Load\n",
    "        \n",
    "        #### Hyperparameters\n",
    "        \n",
    "* ## [2) XGBoost model](#XGB)\n",
    "    \n",
    "    *   \n",
    "        #### Train the model\n",
    "        \n",
    "        #### Test data with best parameters \n",
    "        \n",
    "        #### Confusion Matrix\n",
    "        \n",
    "        #### Tree Plot\n",
    "        \n",
    "        #### Prediction of churn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Introduction and preparation<a class=\"anchor\" id=\"Introduction\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient boosting is a machine learning technique for regression and classification problems, which produces a prediction model in the form of an ensemble of weak prediction models, typically decision trees. It builds the model in a stage-wise fashion like other boosting methods do, and it generalizes them by allowing optimization of an arbitrary differentiable loss function. Source : Wikipedia\n",
    "\n",
    "For the accuracy score, gradient boosted trees generally perform better than Random forests and decision trees.\n",
    "\n",
    "This model is a black box I will use it only if the results are better.\n",
    "\n",
    "Can predict class probabilities and it seems to have good model performance (wins most of the Kaggle competitions)\n",
    "\n",
    "I can easily fine tune and modify the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "# Specify the file path\n",
    "file_path = r'C:\\Users\\msalomo\\OneDrive - NESTLE\\Certificate Machine Learning and Data\\Churn Project\\Notebook output'\n",
    "\n",
    "import xlrd\n",
    "\n",
    "import datetime as dt\n",
    "from datetime import datetime\n",
    "\n",
    "import collections\n",
    "from collections import Counter\n",
    "\n",
    "# Import seaborn\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#libraries\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Import Random Forest Model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "from sklearn import metrics \n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the filename\n",
    "filename = 'BM_noTickets_preprocess.p'\n",
    "\n",
    "# Combine the file path and filename\n",
    "file_path_with_filename = os.path.join(file_path, filename)\n",
    "\n",
    "# Load the pickle file\n",
    "with open(file_path_with_filename, 'rb') as file:\n",
    "    BM_noTickets_preprocess = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pickle file 'X.p'\n",
    "with open(os.path.join(file_path, 'X.p'), 'rb') as file:\n",
    "    X = pickle.load(file)\n",
    "\n",
    "# Load the pickle file 'y.p'\n",
    "with open(os.path.join(file_path, 'y.p'), 'rb') as file:\n",
    "    y = pickle.load(file)\n",
    "\n",
    "# Load the pickle file 'X_tr.p'\n",
    "with open(os.path.join(file_path, 'X_tr.p'), 'rb') as file:\n",
    "    X_tr = pickle.load(file)\n",
    "\n",
    "# Load the pickle file 'y_tr.p'\n",
    "with open(os.path.join(file_path, 'y_tr.p'), 'rb') as file:\n",
    "    y_tr = pickle.load(file)\n",
    "\n",
    "# Load the pickle file 'X_val.p'\n",
    "with open(os.path.join(file_path, 'X_val.p'), 'rb') as file:\n",
    "    X_val = pickle.load(file)\n",
    "\n",
    "# Load the pickle file 'y_val.p'\n",
    "with open(os.path.join(file_path, 'y_val.p'), 'rb') as file:\n",
    "    y_val = pickle.load(file)\n",
    "\n",
    "# Load the pickle file 'X_te.p'\n",
    "with open(os.path.join(file_path, 'X_te.p'), 'rb') as file:\n",
    "    X_te = pickle.load(file)\n",
    "\n",
    "# Load the pickle file 'y_te.p'\n",
    "with open(os.path.join(file_path, 'y_te.p'), 'rb') as file:\n",
    "    y_te = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TA Contract Installation Date</th>\n",
       "      <th>Depreciation Start</th>\n",
       "      <th>TA Contract Start Date</th>\n",
       "      <th>TA Contract End Date</th>\n",
       "      <th>Churn</th>\n",
       "      <th>Service Category_Installation</th>\n",
       "      <th>Service Category_Removal</th>\n",
       "      <th>Service Category_Replacement</th>\n",
       "      <th>INCIDENT_CATEGORY_DESCRIPTION_Customer relocation</th>\n",
       "      <th>INCIDENT_CATEGORY_DESCRIPTION_Exchange / Replacement Sales</th>\n",
       "      <th>...</th>\n",
       "      <th>Generation_Gen. 2</th>\n",
       "      <th>Generation_Legacy</th>\n",
       "      <th>Blueprint Throughput_#-N/A</th>\n",
       "      <th>Blueprint Throughput_High</th>\n",
       "      <th>Blueprint Throughput_Low</th>\n",
       "      <th>Blueprint Throughput_Medium</th>\n",
       "      <th>IP Ownership_Exclusive</th>\n",
       "      <th>IP Ownership_Non-Proprietary</th>\n",
       "      <th>IP Ownership_Propr. Comp.</th>\n",
       "      <th>IP Ownership_Proprietary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1341.0</td>\n",
       "      <td>4079.0</td>\n",
       "      <td>1341.0</td>\n",
       "      <td>-485.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1949.0</td>\n",
       "      <td>1067.0</td>\n",
       "      <td>1939.0</td>\n",
       "      <td>271.534348</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1949.0</td>\n",
       "      <td>488.0</td>\n",
       "      <td>1939.0</td>\n",
       "      <td>271.534348</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1949.0</td>\n",
       "      <td>1491.0</td>\n",
       "      <td>1939.0</td>\n",
       "      <td>271.534348</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1949.0</td>\n",
       "      <td>3502.0</td>\n",
       "      <td>1939.0</td>\n",
       "      <td>271.534348</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1567 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   TA Contract Installation Date  Depreciation Start  TA Contract Start Date  \\\n",
       "0                         1341.0              4079.0                  1341.0   \n",
       "1                         1949.0              1067.0                  1939.0   \n",
       "2                         1949.0               488.0                  1939.0   \n",
       "3                         1949.0              1491.0                  1939.0   \n",
       "4                         1949.0              3502.0                  1939.0   \n",
       "\n",
       "   TA Contract End Date  Churn  Service Category_Installation  \\\n",
       "0           -485.000000  False                            0.0   \n",
       "1            271.534348  False                            2.0   \n",
       "2            271.534348  False                            2.0   \n",
       "3            271.534348  False                            0.0   \n",
       "4            271.534348  False                            0.0   \n",
       "\n",
       "   Service Category_Removal  Service Category_Replacement  \\\n",
       "0                       0.0                           0.0   \n",
       "1                       0.0                           0.0   \n",
       "2                       0.0                           0.0   \n",
       "3                       0.0                           0.0   \n",
       "4                       0.0                           0.0   \n",
       "\n",
       "   INCIDENT_CATEGORY_DESCRIPTION_Customer relocation  \\\n",
       "0                                                0.0   \n",
       "1                                                0.0   \n",
       "2                                                0.0   \n",
       "3                                                0.0   \n",
       "4                                                0.0   \n",
       "\n",
       "   INCIDENT_CATEGORY_DESCRIPTION_Exchange / Replacement Sales  ...  \\\n",
       "0                                                0.0           ...   \n",
       "1                                                0.0           ...   \n",
       "2                                                0.0           ...   \n",
       "3                                                0.0           ...   \n",
       "4                                                0.0           ...   \n",
       "\n",
       "   Generation_Gen. 2  Generation_Legacy  Blueprint Throughput_#-N/A  \\\n",
       "0                  0                  0                           0   \n",
       "1                  1                  0                           0   \n",
       "2                  1                  0                           0   \n",
       "3                  1                  0                           0   \n",
       "4                  0                  1                           0   \n",
       "\n",
       "   Blueprint Throughput_High  Blueprint Throughput_Low  \\\n",
       "0                          0                         1   \n",
       "1                          0                         0   \n",
       "2                          0                         0   \n",
       "3                          0                         1   \n",
       "4                          0                         1   \n",
       "\n",
       "   Blueprint Throughput_Medium  IP Ownership_Exclusive  \\\n",
       "0                            0                       0   \n",
       "1                            1                       1   \n",
       "2                            1                       1   \n",
       "3                            0                       0   \n",
       "4                            0                       0   \n",
       "\n",
       "   IP Ownership_Non-Proprietary  IP Ownership_Propr. Comp.  \\\n",
       "0                             0                          0   \n",
       "1                             0                          0   \n",
       "2                             0                          0   \n",
       "3                             0                          0   \n",
       "4                             1                          0   \n",
       "\n",
       "   IP Ownership_Proprietary  \n",
       "0                         1  \n",
       "1                         0  \n",
       "2                         0  \n",
       "3                         1  \n",
       "4                         0  \n",
       "\n",
       "[5 rows x 1567 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BM_noTickets_preprocess.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### class xgboost.XGBClassifier(**kwargs)\n",
    "##### Bases: xgboost.sklearn.XGBModel, object\n",
    "\n",
    "Implementation of the scikit-learn API for XGBoost classification.\n",
    "\n",
    "##### Parameters\n",
    "\n",
    "    n_estimators (int) – Number of boosting rounds.\n",
    "\n",
    "    use_label_encoder (bool) – (Deprecated) Use the label encoder from scikit-learn to encode the labels. For new code, we recommend that you set this parameter to False.\n",
    "\n",
    "    max_depth (int) – Maximum tree depth for base learners.\n",
    "\n",
    "    learning_rate (float) – Boosting learning rate (xgb’s “eta”)\n",
    "\n",
    "    verbosity (int) – The degree of verbosity. Valid values are 0 (silent) - 3 (debug).\n",
    "\n",
    "    objective (string or callable) – Specify the learning task and the corresponding learning objective or a custom objective function to be used (see note below).\n",
    "\n",
    "    booster (string) – Specify which booster to use: gbtree, gblinear or dart.\n",
    "    \n",
    "\"gbtree booster uses version of regression tree as a weak learner\n",
    "gblinear uses (generalized) linear regression with l1&l2 shrinkage. But since it’s an additive process, and since linear regression is an additive model itself, only the combined linear model coefficients are retained.\n",
    "dart adopted dropout method from neural networks to boosted regression rees. There are several parameters to be tuned:\n",
    "•\tskip_drop(default = 0, range [0, 1]) is the probability of skipping dropout. It has a higher priority than other DART parameters. If skip_drop = 1, the dropout procedure would be skipped and dart is the same as gbtree.\n",
    "•\tIf skip_drop≠0, rate_drop (default = 0, range [0, 1]) will drop a fraction of the trees before the model update in every iteration. dropout makes dart between gbtree and random forest: “If no tree is dropped, dart is the same as (gbtree); if all the trees are dropped, dart is no different than random forest.”\"\n",
    "Source : \n",
    "https://xzz201920.medium.com/xgbosst-booster-gbtree-v-s-dart-v-s-gblinear-82d8fcbb07d2\n",
    "\n",
    "\n",
    "    tree_method (string) – Specify which tree method to use. Default to auto. If this parameter is set to default, XGBoost will choose the most conservative option available. It’s recommended to study this option from parameters document.\n",
    "\n",
    "    n_jobs (int) – Number of parallel threads used to run xgboost. When used with other Scikit-Learn algorithms like grid search, you may choose which algorithm to parallelize and balance the threads. Creating thread contention will significantly slow dowm both algorithms.\n",
    "\n",
    "    gamma (float) – Minimum loss reduction required to make a further partition on a leaf node of the tree.\n",
    "\n",
    "    min_child_weight (float) – Minimum sum of instance weight(hessian) needed in a child.\n",
    "\n",
    "    max_delta_step (int) – Maximum delta step we allow each tree’s weight estimation to be.\n",
    "\n",
    "    subsample (float) – Subsample ratio of the training instance.\n",
    "\n",
    "    colsample_bytree (float) – Subsample ratio of columns when constructing each tree.\n",
    "\n",
    "    colsample_bylevel (float) – Subsample ratio of columns for each level.\n",
    "\n",
    "    colsample_bynode (float) – Subsample ratio of columns for each split.\n",
    "\n",
    "    reg_alpha (float (xgb's alpha)) – L1 regularization term on weights\n",
    "\n",
    "    reg_lambda (float (xgb's lambda)) – L2 regularization term on weights\n",
    "\n",
    "    scale_pos_weight (float) – Balancing of positive and negative weights.\n",
    "\n",
    "    base_score – The initial prediction score of all instances, global bias.\n",
    "\n",
    "    random_state (int) – Random number seed.\n",
    "\n",
    "\n",
    "    missing (float, default np.nan) – Value in the data which needs to be present as a missing value.\n",
    "\n",
    "    num_parallel_tree (int) – Used for boosting random forest.\n",
    "\n",
    "    monotone_constraints (str) – Constraint of variable monotonicity. See tutorial for more information.\n",
    "\n",
    "    interaction_constraints (str) – Constraints for interaction representing permitted interactions. The constraints must be specified in the form of a nest list, e.g. [[0, 1], [2, 3, 4]], where each inner list is a group of indices of features that are allowed to interact with each other. See tutorial for more information\n",
    "\n",
    "    importance_type (string, default \"gain\") – The feature importance type for the feature_importances_ property: either “gain”, “weight”, “cover”, “total_gain” or “total_cover”.\n",
    "\n",
    "Source :\n",
    "Full documentation of parameters can be found here: https://github.com/dmlc/xgboost/blob/master/doc/parameter.rst.\n",
    "\n",
    "and https://xgboost.readthedocs.io/en/latest/python/python_api.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) XGBoost model<a class=\"anchor\" id=\"XGB\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### libraries\n",
    "#from sklearn.tree import XGBClassifier\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "# Define a set of reasonable values\n",
    "#n_estimators = range(10,200,50)\n",
    "\n",
    "booster = ['gbtree', 'gblinear', 'dart']\n",
    "eta = [0.01, 0.1, 0.3]\n",
    "\n",
    "# Define a parameter grid of values\n",
    "grid = ParameterGrid({\n",
    "    'XGB__booster' : booster,\n",
    "    'XGB__eta': eta\n",
    "}\n",
    ")\n",
    " \n",
    "# Create pipeline, XGBoost classifier\n",
    "pipe = Pipeline([\n",
    "#('scaler', StandardScaler()),\n",
    "('XGB', XGBClassifier(verbosity =0\n",
    "    #scale_pos_weight=weight\n",
    "))\n",
    "])\n",
    "\n",
    "   \n",
    "# Save accuracy on test set\n",
    "test_scores = []\n",
    "\n",
    "for params_dict in grid:\n",
    "    # Set parameters\n",
    "    pipe.set_params(**params_dict)\n",
    "\n",
    "    # Fit a k-NN classifier\n",
    "    pipe.fit(X_tr, y_tr)\n",
    "\n",
    "    # Save accuracy on validation set\n",
    "    params_dict['accuracy'] = pipe.score(X_val, y_val)\n",
    "    # Save f1 score on validation set\n",
    "    # predict test instances\n",
    "    y_pred = pipe.predict(X_val)\n",
    "    params_dict['f1_macro'] = metrics.f1_score(y_val, y_pred, average='macro')\n",
    "    \n",
    "    # Save result\n",
    "    test_scores.append(params_dict)\n",
    "    \n",
    "# Create DataFrame with test scores\n",
    "scores_df = pd.DataFrame(test_scores)\n",
    "\n",
    "# Top five scores\n",
    "scores_df.sort_values(by='f1_macro', ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will try to improve the model with other parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# Define a set of reasonable values\n",
    "#n_estimators = range(10,200,50)\n",
    "\n",
    "booster = ['dart'] # 'gblinear' is removed, worst results with low score\n",
    "eta = [0.1]  # 0.01\n",
    "max_depth  = [6, 20, 50] #5, 6, 10\n",
    "subsample = [0.5, 0.85] #0.25, 0.5, 0.9\n",
    "min_child_weight =[1, 2] # 5, 10, 20\n",
    "\n",
    "# Define a parameter grid of values\n",
    "grid = ParameterGrid({\n",
    "    'XGB__booster' : booster,\n",
    "    'XGB__eta': eta,\n",
    "    'XGB__max_depth': max_depth,\n",
    "    'XGB__subsample': subsample,\n",
    "    'XGB__min_child_weight': min_child_weight\n",
    "}\n",
    ")\n",
    " \n",
    "# Create pipeline, XGBoost classifier\n",
    "pipe = Pipeline([\n",
    "#('scaler', StandardScaler()),\n",
    "('XGB', XGBClassifier(verbosity =0\n",
    "    #scale_pos_weight=weight\n",
    "))\n",
    "])\n",
    "\n",
    "   \n",
    "# Save accuracy on test set\n",
    "test_scores = []\n",
    "\n",
    "for params_dict in grid:\n",
    "    # Set parameters\n",
    "    pipe.set_params(**params_dict)\n",
    "\n",
    "    # Fit a k-NN classifier\n",
    "    pipe.fit(X_tr, y_tr)\n",
    "\n",
    "    # Save accuracy on validation set\n",
    "    params_dict['accuracy'] = pipe.score(X_val, y_val)\n",
    "    # Save f1 score on validation set\n",
    "    # predict test instances\n",
    "    y_pred = pipe.predict(X_val)\n",
    "    params_dict['f1_macro'] = metrics.f1_score(y_val, y_pred, average='macro')\n",
    "    \n",
    "    # Save result\n",
    "    test_scores.append(params_dict)\n",
    "    \n",
    "# Create DataFrame with test scores\n",
    "scores_df = pd.DataFrame(test_scores)\n",
    "\n",
    "# Top five scores\n",
    "scores_df.sort_values(by='f1_macro', ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test data with best parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I test the model with the best parameters score from the validation data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TO transform into text - made to avoid preious long steps\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "# Define a set of reasonable values\n",
    "#n_estimators = range(10,200,50)\n",
    "\n",
    " \n",
    "# Create pipeline, XGBoost classifier\n",
    "pipe = Pipeline([\n",
    "#('scaler', StandardScaler()),\n",
    "('XGB', XGBClassifier(verbosity =0\n",
    "    #scale_pos_weight=weight\n",
    "))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>XGB__booster</th>\n",
       "      <th>XGB__eta</th>\n",
       "      <th>XGB__max_depth</th>\n",
       "      <th>XGB__subsample</th>\n",
       "      <th>XGB__min_child_weight</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.3</td>\n",
       "      <td>30</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1</td>\n",
       "      <td>0.894318</td>\n",
       "      <td>0.893244</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  XGB__booster  XGB__eta  XGB__max_depth  XGB__subsample  \\\n",
       "0       gbtree       0.3              30            0.75   \n",
       "\n",
       "   XGB__min_child_weight  accuracy  f1_macro  \n",
       "0                      1  0.894318  0.893244  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### libraries\n",
    "#from sklearn.tree import XGBClassifier\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "# Define a parameter grid of values\n",
    "params_dict = {\n",
    "    'XGB__booster' : 'gbtree',\n",
    "    'XGB__eta': 0.3,\n",
    "    'XGB__max_depth': 30,\n",
    "    'XGB__subsample': 0.75,\n",
    "    'XGB__min_child_weight': 1\n",
    "}\n",
    "\n",
    " \n",
    "# Create pipeline, XGBoost classifier\n",
    "pipe = Pipeline([\n",
    "#('scaler', StandardScaler()),\n",
    "('XGB', XGBClassifier(verbosity =0\n",
    "    #scale_pos_weight=weight\n",
    "))\n",
    "])\n",
    "\n",
    "# Save accuracy on test set\n",
    "test_scores = []   \n",
    "\n",
    "pipe.set_params(**params_dict)\n",
    "\n",
    "# Fit a k-NN classifier\n",
    "pipe.fit(X_tr, y_tr)\n",
    "\n",
    "# Save accuracy on validation set\n",
    "params_dict['accuracy'] = pipe.score(X_te, y_te)\n",
    "\n",
    "# Save f1 score on test set\n",
    "# predict test instances\n",
    "y_pred = pipe.predict(X_te)\n",
    "\n",
    "params_dict['f1_macro'] = metrics.f1_score(y_te, y_pred, average='macro')\n",
    "    \n",
    "# Save result\n",
    "test_scores.append(params_dict)\n",
    "    \n",
    "# Create DataFrame with test scores\n",
    "scores_df = pd.DataFrame(test_scores)\n",
    "\n",
    "# Top five scores\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy is 93% and F1 macro is 82%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# F1_score\n",
    "XGB_F1Macro = params_dict['f1_macro']\n",
    "\n",
    "# Accuracy\n",
    "XGB_accuracy = params_dict['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_Results: [0.42674315 0.         0.         0.         0.         0.89324379\n",
      " 0.         0.        ]\n",
      "Accuracy: [0.4895943  0.         0.         0.         0.         0.89431795\n",
      " 0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "# Load the npz file for results\n",
    "# Specify the filename\n",
    "filename = 'Results.npz'\n",
    "\n",
    "# Combine the file path and filename\n",
    "file_path_with_filename = os.path.join(file_path, filename)\n",
    "\n",
    "# Load the npz file for results\n",
    "with np.load(file_path_with_filename, allow_pickle=False) as npz_file:\n",
    "    F1Score = npz_file['test_F1Score']\n",
    "    accuracy = npz_file['test_accuracy']\n",
    "    models = npz_file['models']\n",
    "    \n",
    "# Fill the calculated result value\n",
    "F1Score[5] = XGB_F1Macro\n",
    "accuracy[5] = XGB_accuracy\n",
    "\n",
    "print('F1_Results:', F1Score)\n",
    "print('Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify the Numpy array\n",
    "#Model = models #unchanged\n",
    "Result = F1Score\n",
    "Accuracy = accuracy\n",
    "\n",
    "# Store the changes in the results npz file\n",
    "np.savez('Results.npz', models = models, test_F1Score = Result,  test_accuracy = Accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['models', 'test_F1Score', 'test_accuracy']\n",
      "Models: ['Baseline' 'Logistic Regression' 'KNeighbors' 'Decision Tree'\n",
      " 'Random Forest' 'XGBoost' 'SelectedModel_wTickets'\n",
      " 'SelectedModel_wTickets&Telemetry']\n",
      "F1_Results: [0.42674315 0.         0.         0.         0.         0.89324379\n",
      " 0.         0.        ]\n",
      "Accuracy: [0.4895943  0.         0.         0.         0.         0.89431795\n",
      " 0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "# Check the refreshed results\n",
    "# Load the npz file for results\n",
    "with np.load('Results.npz', allow_pickle=False) as npz_file:\n",
    "    # It's a dictionary-like object    \n",
    "    print(list(npz_file.keys()))\n",
    "    # Load the arrays\n",
    "    print('Models:', npz_file['models'])\n",
    "    print('F1_Results:', npz_file['test_F1Score'])\n",
    "    print('Accuracy:', npz_file['test_accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[26931  2241]\n",
      " [ 3482 21499]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False      0.886     0.923     0.904     29172\n",
      "        True      0.906     0.861     0.883     24981\n",
      "\n",
      "    accuracy                          0.894     54153\n",
      "   macro avg      0.896     0.892     0.893     54153\n",
      "weighted avg      0.895     0.894     0.894     54153\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Classification reports and confusion matrices are commonly used for reporting the performance of classifiers when working with imbalanced datasets.\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(metrics.confusion_matrix(y_te, y_pred))\n",
    "\n",
    "# Print the precision and recall, among other metrics\n",
    "print(metrics.classification_report(y_te, y_pred, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>False Condition</th>\n",
       "      <th>True Condition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Predicted False</th>\n",
       "      <td>26931</td>\n",
       "      <td>3482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predicted True</th>\n",
       "      <td>2241</td>\n",
       "      <td>21499</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 False Condition  True Condition\n",
       "Predicted False            26931            3482\n",
       "Predicted True              2241           21499"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Classification reports and confusion matrices are commonly used for reporting the performance of classifiers when working with imbalanced datasets.\n",
    "ConfMat_df = pd.DataFrame(metrics.confusion_matrix(y_te, y_pred).T, columns=['False Condition', 'True Condition'],index=['Predicted False', 'Predicted True'])\n",
    "ConfMat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the filename\n",
    "filename = 'XGBoost_ConfMat_df.p'\n",
    "\n",
    "# Combine the file path and filename\n",
    "file_path_with_filename = os.path.join(file_path, filename)\n",
    "\n",
    "# Save the DataFrame into a pickle file\n",
    "with open(file_path_with_filename, 'wb') as file:\n",
    "    pickle.dump(ConfMat_df, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction of churn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Need the one in the same format, so with removed Sales Org\n",
    "# Load the pickle file\n",
    "with open('BM_noTicketsWOSO.p', 'rb') as file:\n",
    "    BM_noTicketsWOSO = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the filename\n",
    "filename = 'BeverageMachine_withSerial.p'\n",
    "\n",
    "# Combine the file path and filename\n",
    "file_path_with_filename = os.path.join(file_path, filename)\n",
    "\n",
    "# Load the pickle file\n",
    "with open(file_path_with_filename, 'rb') as file:\n",
    "    BeverageMachine_withSerial = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>False</th>\n",
       "      <th>True</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Serial ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>132020210</th>\n",
       "      <td>0.998055</td>\n",
       "      <td>0.001945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19O0046537</th>\n",
       "      <td>0.850769</td>\n",
       "      <td>0.149231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23O0024982</th>\n",
       "      <td>0.975883</td>\n",
       "      <td>0.024117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HK10020559</th>\n",
       "      <td>0.898539</td>\n",
       "      <td>0.101461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4410837</th>\n",
       "      <td>0.978279</td>\n",
       "      <td>0.021721</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               False      True\n",
       "Serial ID                     \n",
       "132020210   0.998055  0.001945\n",
       "19O0046537  0.850769  0.149231\n",
       "23O0024982  0.975883  0.024117\n",
       "HK10020559  0.898539  0.101461\n",
       "4410837     0.978279  0.021721"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name = ['False', 'True']\n",
    "No=BeverageMachine_withSerial['Serial ID']\n",
    "predictions = pipe.predict_proba(X)\n",
    "# With two column indices, values same  \n",
    "# as dictionary keys \n",
    "df2 = pd.DataFrame(predictions, index=No ,columns = name) \n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial ID</th>\n",
       "      <th>False</th>\n",
       "      <th>True</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>132020210</td>\n",
       "      <td>0.998055</td>\n",
       "      <td>0.001945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19O0046537</td>\n",
       "      <td>0.850769</td>\n",
       "      <td>0.149231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23O0024982</td>\n",
       "      <td>0.975883</td>\n",
       "      <td>0.024117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HK10020559</td>\n",
       "      <td>0.898539</td>\n",
       "      <td>0.101461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4410837</td>\n",
       "      <td>0.978279</td>\n",
       "      <td>0.021721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270759</th>\n",
       "      <td>7010049071</td>\n",
       "      <td>0.015675</td>\n",
       "      <td>0.984325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270760</th>\n",
       "      <td>7010042493</td>\n",
       "      <td>0.360982</td>\n",
       "      <td>0.639018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270761</th>\n",
       "      <td>7010059106</td>\n",
       "      <td>0.260657</td>\n",
       "      <td>0.739343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270762</th>\n",
       "      <td>7010053961</td>\n",
       "      <td>0.278136</td>\n",
       "      <td>0.721864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270763</th>\n",
       "      <td>7010053960</td>\n",
       "      <td>0.015947</td>\n",
       "      <td>0.984053</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>270764 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Serial ID     False      True\n",
       "0        132020210  0.998055  0.001945\n",
       "1       19O0046537  0.850769  0.149231\n",
       "2       23O0024982  0.975883  0.024117\n",
       "3       HK10020559  0.898539  0.101461\n",
       "4          4410837  0.978279  0.021721\n",
       "...            ...       ...       ...\n",
       "270759  7010049071  0.015675  0.984325\n",
       "270760  7010042493  0.360982  0.639018\n",
       "270761  7010059106  0.260657  0.739343\n",
       "270762  7010053961  0.278136  0.721864\n",
       "270763  7010053960  0.015947  0.984053\n",
       "\n",
       "[270764 rows x 3 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3 = df2.reset_index(level=None)\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 270764 entries, 0 to 270763\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count   Dtype  \n",
      "---  ------     --------------   -----  \n",
      " 0   index      270764 non-null  int64  \n",
      " 1   Serial ID  270764 non-null  object \n",
      " 2   False      270764 non-null  float32\n",
      " 3   True       270764 non-null  float32\n",
      "dtypes: float32(2), int64(1), object(1)\n",
      "memory usage: 6.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df3.reset_index(inplace=True)\n",
    "df3.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df21 = pd.DataFrame(BeverageMachine_withSerial[['Serial ID','Churn']]).reset_index(level=None)\n",
    "df21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Serial ID</th>\n",
       "      <th>Churn</th>\n",
       "      <th>Sales Organisation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>132020210</td>\n",
       "      <td>False</td>\n",
       "      <td>Nestlé Austria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>19O0046537</td>\n",
       "      <td>False</td>\n",
       "      <td>Nestlé PH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>23O0024982</td>\n",
       "      <td>False</td>\n",
       "      <td>Nestlé PH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>HK10020559</td>\n",
       "      <td>False</td>\n",
       "      <td>Nestle Hong Kong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4410837</td>\n",
       "      <td>False</td>\n",
       "      <td>NP-Hungary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270759</th>\n",
       "      <td>270759</td>\n",
       "      <td>7010049071</td>\n",
       "      <td>True</td>\n",
       "      <td>Pakistan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270760</th>\n",
       "      <td>270760</td>\n",
       "      <td>7010042493</td>\n",
       "      <td>True</td>\n",
       "      <td>Pakistan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270761</th>\n",
       "      <td>270761</td>\n",
       "      <td>7010059106</td>\n",
       "      <td>True</td>\n",
       "      <td>Pakistan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270762</th>\n",
       "      <td>270762</td>\n",
       "      <td>7010053961</td>\n",
       "      <td>True</td>\n",
       "      <td>Pakistan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270763</th>\n",
       "      <td>270763</td>\n",
       "      <td>7010053960</td>\n",
       "      <td>True</td>\n",
       "      <td>Pakistan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>270764 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         index   Serial ID  Churn Sales Organisation\n",
       "0            0   132020210  False     Nestlé Austria\n",
       "1            1  19O0046537  False          Nestlé PH\n",
       "2            2  23O0024982  False          Nestlé PH\n",
       "3            3  HK10020559  False   Nestle Hong Kong\n",
       "4            4     4410837  False         NP-Hungary\n",
       "...        ...         ...    ...                ...\n",
       "270759  270759  7010049071   True           Pakistan\n",
       "270760  270760  7010042493   True           Pakistan\n",
       "270761  270761  7010059106   True           Pakistan\n",
       "270762  270762  7010053961   True           Pakistan\n",
       "270763  270763  7010053960   True           Pakistan\n",
       "\n",
       "[270764 rows x 4 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df21 = pd.DataFrame(BeverageMachine_withSerial[['Serial ID','Churn', 'Sales Organisation']]).reset_index(level=None)\n",
    "df21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 270764 entries, 0 to 270763\n",
      "Data columns (total 4 columns):\n",
      " #   Column              Non-Null Count   Dtype \n",
      "---  ------              --------------   ----- \n",
      " 0   index               270764 non-null  int64 \n",
      " 1   Serial ID           270764 non-null  object\n",
      " 2   Churn               270764 non-null  bool  \n",
      " 3   Sales Organisation  270764 non-null  object\n",
      "dtypes: bool(1), int64(1), object(2)\n",
      "memory usage: 6.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df21.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3['Serial ID'] = df3['Serial ID'].astype('str')\n",
    "df21['Serial ID'] = df21['Serial ID'].astype('str')\n",
    "df3['index'] = df3['index'].astype('str')\n",
    "df21['index'] = df21['index'].astype('str')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3['KeyIndSer'] = df3['index'] + \"-\" + df3['Serial ID']\n",
    "df21['KeyIndSer'] = df21['index'] + \"-\" + df21['Serial ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = pd.merge(df3, df21, how='left', left_on = ['KeyIndSer'], right_on = ['KeyIndSer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 270764 entries, 0 to 270763\n",
      "Data columns (total 9 columns):\n",
      " #   Column              Non-Null Count   Dtype  \n",
      "---  ------              --------------   -----  \n",
      " 0   index_x             270764 non-null  object \n",
      " 1   Serial ID_x         270764 non-null  object \n",
      " 2   False               270764 non-null  float32\n",
      " 3   True                270764 non-null  float32\n",
      " 4   KeyIndSer           270764 non-null  object \n",
      " 5   index_y             270764 non-null  object \n",
      " 6   Serial ID_y         270764 non-null  object \n",
      " 7   Churn               270764 non-null  bool   \n",
      " 8   Sales Organisation  270764 non-null  object \n",
      "dtypes: bool(1), float32(2), object(6)\n",
      "memory usage: 16.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df4.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.to_csv(r'C:\\Users\\msalomo\\predictions-Churn-XGBOOST.csv', index = False, header=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forests generally outperform decision trees, but their accuracy is lower than gradient boosted trees. But in the end I might still use Decision Tree or Random Forest because the score is not based on the accuracy but on the F1_macro score. Here in this case the best model is Random Forest."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
