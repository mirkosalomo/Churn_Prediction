{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone proposal by Mirko Salomon \n",
    "\n",
    "# BEVERAGE MACHINE CHURN PREDICTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ## [1) Introduction and preparation](#Introduction) \n",
    "\n",
    "    *   \n",
    "        #### Data Load\n",
    "        \n",
    "        #### Hyperparameters\n",
    "        \n",
    "* ## [2) XGBoost model](#XGB)\n",
    "    \n",
    "    *   \n",
    "        #### Train the model\n",
    "        \n",
    "        #### Test data with best parameters \n",
    "        \n",
    "        #### Confusion Matrix\n",
    "        \n",
    "        #### Tree Plot\n",
    "        \n",
    "        #### Prediction of churn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Introduction and preparation<a class=\"anchor\" id=\"Introduction\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient boosting is a machine learning technique for regression and classification problems, which produces a prediction model in the form of an ensemble of weak prediction models, typically decision trees. It builds the model in a stage-wise fashion like other boosting methods do, and it generalizes them by allowing optimization of an arbitrary differentiable loss function. Source : Wikipedia\n",
    "\n",
    "For the accuracy score, gradient boosted trees generally perform better than Random forests and decision trees.\n",
    "\n",
    "This model is a black box I will use it only if the results are better.\n",
    "\n",
    "Can predict class probabilities and it seems to have good model performance (wins most of the Kaggle competitions)\n",
    "\n",
    "I can easily fine tune and modify the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "# Specify the file path\n",
    "file_path = r'C:\\Users\\msalomo\\OneDrive - NESTLE\\Certificate Machine Learning and Data\\Churn Project\\Notebook output'\n",
    "\n",
    "import xlrd\n",
    "\n",
    "import datetime as dt\n",
    "from datetime import datetime\n",
    "\n",
    "import collections\n",
    "from collections import Counter\n",
    "\n",
    "# Import seaborn\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#libraries\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Import Random Forest Model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "from sklearn import metrics \n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the filename\n",
    "filename = 'BM_noTickets_preprocess.p'\n",
    "\n",
    "# Combine the file path and filename\n",
    "file_path_with_filename = os.path.join(file_path, filename)\n",
    "\n",
    "# Load the pickle file\n",
    "with open(file_path_with_filename, 'rb') as file:\n",
    "    BM_noTickets_preprocess = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pickle file 'X.p'\n",
    "with open(os.path.join(file_path, 'X.p'), 'rb') as file:\n",
    "    X = pickle.load(file)\n",
    "\n",
    "# Load the pickle file 'y.p'\n",
    "with open(os.path.join(file_path, 'y.p'), 'rb') as file:\n",
    "    y = pickle.load(file)\n",
    "\n",
    "# Load the pickle file 'X_tr.p'\n",
    "with open(os.path.join(file_path, 'X_tr.p'), 'rb') as file:\n",
    "    X_tr = pickle.load(file)\n",
    "\n",
    "# Load the pickle file 'y_tr.p'\n",
    "with open(os.path.join(file_path, 'y_tr.p'), 'rb') as file:\n",
    "    y_tr = pickle.load(file)\n",
    "\n",
    "# Load the pickle file 'X_val.p'\n",
    "with open(os.path.join(file_path, 'X_val.p'), 'rb') as file:\n",
    "    X_val = pickle.load(file)\n",
    "\n",
    "# Load the pickle file 'y_val.p'\n",
    "with open(os.path.join(file_path, 'y_val.p'), 'rb') as file:\n",
    "    y_val = pickle.load(file)\n",
    "\n",
    "# Load the pickle file 'X_te.p'\n",
    "with open(os.path.join(file_path, 'X_te.p'), 'rb') as file:\n",
    "    X_te = pickle.load(file)\n",
    "\n",
    "# Load the pickle file 'y_te.p'\n",
    "with open(os.path.join(file_path, 'y_te.p'), 'rb') as file:\n",
    "    y_te = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TA Contract Installation Date</th>\n",
       "      <th>Depreciation Start</th>\n",
       "      <th>TA Contract Start Date</th>\n",
       "      <th>TA Contract End Date</th>\n",
       "      <th>Churn</th>\n",
       "      <th>Service Category_Installation</th>\n",
       "      <th>Service Category_Removal</th>\n",
       "      <th>Service Category_Replacement</th>\n",
       "      <th>INCIDENT_CATEGORY_DESCRIPTION_Customer relocation</th>\n",
       "      <th>INCIDENT_CATEGORY_DESCRIPTION_Exchange / Replacement Sales</th>\n",
       "      <th>...</th>\n",
       "      <th>Generation_Gen. 2</th>\n",
       "      <th>Generation_Legacy</th>\n",
       "      <th>Blueprint Throughput_%23-N/A</th>\n",
       "      <th>Blueprint Throughput_High</th>\n",
       "      <th>Blueprint Throughput_Low</th>\n",
       "      <th>Blueprint Throughput_Medium</th>\n",
       "      <th>IP Ownership_Exclusive</th>\n",
       "      <th>IP Ownership_Non-Proprietary</th>\n",
       "      <th>IP Ownership_Propr. Comp.</th>\n",
       "      <th>IP Ownership_Proprietary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1799.0</td>\n",
       "      <td>3073.0</td>\n",
       "      <td>1790.0</td>\n",
       "      <td>55.319629</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1799.0</td>\n",
       "      <td>2921.0</td>\n",
       "      <td>1790.0</td>\n",
       "      <td>55.319629</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1799.0</td>\n",
       "      <td>2921.0</td>\n",
       "      <td>1790.0</td>\n",
       "      <td>55.319629</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1799.0</td>\n",
       "      <td>2951.0</td>\n",
       "      <td>1790.0</td>\n",
       "      <td>55.319629</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1799.0</td>\n",
       "      <td>2951.0</td>\n",
       "      <td>1790.0</td>\n",
       "      <td>55.319629</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1389 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   TA Contract Installation Date  Depreciation Start  TA Contract Start Date  \\\n",
       "0                         1799.0              3073.0                  1790.0   \n",
       "1                         1799.0              2921.0                  1790.0   \n",
       "2                         1799.0              2921.0                  1790.0   \n",
       "3                         1799.0              2951.0                  1790.0   \n",
       "4                         1799.0              2951.0                  1790.0   \n",
       "\n",
       "   TA Contract End Date  Churn  Service Category_Installation  \\\n",
       "0             55.319629  False                            0.0   \n",
       "1             55.319629  False                            0.0   \n",
       "2             55.319629  False                            1.0   \n",
       "3             55.319629  False                            1.0   \n",
       "4             55.319629  False                            0.0   \n",
       "\n",
       "   Service Category_Removal  Service Category_Replacement  \\\n",
       "0                       0.0                           0.0   \n",
       "1                       0.0                           0.0   \n",
       "2                       0.0                           0.0   \n",
       "3                       0.0                           0.0   \n",
       "4                       0.0                           0.0   \n",
       "\n",
       "   INCIDENT_CATEGORY_DESCRIPTION_Customer relocation  \\\n",
       "0                                                0.0   \n",
       "1                                                0.0   \n",
       "2                                                0.0   \n",
       "3                                                0.0   \n",
       "4                                                0.0   \n",
       "\n",
       "   INCIDENT_CATEGORY_DESCRIPTION_Exchange / Replacement Sales  ...  \\\n",
       "0                                                0.0           ...   \n",
       "1                                                0.0           ...   \n",
       "2                                                0.0           ...   \n",
       "3                                                0.0           ...   \n",
       "4                                                0.0           ...   \n",
       "\n",
       "   Generation_Gen. 2  Generation_Legacy  Blueprint Throughput_%23-N/A  \\\n",
       "0                  0                  0                             0   \n",
       "1                  0                  0                             0   \n",
       "2                  0                  0                             0   \n",
       "3                  0                  0                             0   \n",
       "4                  0                  0                             0   \n",
       "\n",
       "   Blueprint Throughput_High  Blueprint Throughput_Low  \\\n",
       "0                          0                         0   \n",
       "1                          0                         0   \n",
       "2                          0                         0   \n",
       "3                          0                         0   \n",
       "4                          0                         0   \n",
       "\n",
       "   Blueprint Throughput_Medium  IP Ownership_Exclusive  \\\n",
       "0                            1                       0   \n",
       "1                            1                       0   \n",
       "2                            1                       0   \n",
       "3                            1                       0   \n",
       "4                            1                       0   \n",
       "\n",
       "   IP Ownership_Non-Proprietary  IP Ownership_Propr. Comp.  \\\n",
       "0                             0                          0   \n",
       "1                             0                          0   \n",
       "2                             0                          0   \n",
       "3                             0                          0   \n",
       "4                             0                          0   \n",
       "\n",
       "   IP Ownership_Proprietary  \n",
       "0                         1  \n",
       "1                         1  \n",
       "2                         1  \n",
       "3                         1  \n",
       "4                         1  \n",
       "\n",
       "[5 rows x 1389 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BM_noTickets_preprocess.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### class xgboost.XGBClassifier(**kwargs)\n",
    "##### Bases: xgboost.sklearn.XGBModel, object\n",
    "\n",
    "Implementation of the scikit-learn API for XGBoost classification.\n",
    "\n",
    "##### Parameters\n",
    "\n",
    "    n_estimators (int) – Number of boosting rounds.\n",
    "\n",
    "    use_label_encoder (bool) – (Deprecated) Use the label encoder from scikit-learn to encode the labels. For new code, we recommend that you set this parameter to False.\n",
    "\n",
    "    max_depth (int) – Maximum tree depth for base learners.\n",
    "\n",
    "    learning_rate (float) – Boosting learning rate (xgb’s “eta”)\n",
    "\n",
    "    verbosity (int) – The degree of verbosity. Valid values are 0 (silent) - 3 (debug).\n",
    "\n",
    "    objective (string or callable) – Specify the learning task and the corresponding learning objective or a custom objective function to be used (see note below).\n",
    "\n",
    "    booster (string) – Specify which booster to use: gbtree, gblinear or dart.\n",
    "    \n",
    "\"gbtree booster uses version of regression tree as a weak learner\n",
    "gblinear uses (generalized) linear regression with l1&l2 shrinkage. But since it’s an additive process, and since linear regression is an additive model itself, only the combined linear model coefficients are retained.\n",
    "dart adopted dropout method from neural networks to boosted regression rees. There are several parameters to be tuned:\n",
    "•\tskip_drop(default = 0, range [0, 1]) is the probability of skipping dropout. It has a higher priority than other DART parameters. If skip_drop = 1, the dropout procedure would be skipped and dart is the same as gbtree.\n",
    "•\tIf skip_drop≠0, rate_drop (default = 0, range [0, 1]) will drop a fraction of the trees before the model update in every iteration. dropout makes dart between gbtree and random forest: “If no tree is dropped, dart is the same as (gbtree); if all the trees are dropped, dart is no different than random forest.”\"\n",
    "Source : \n",
    "https://xzz201920.medium.com/xgbosst-booster-gbtree-v-s-dart-v-s-gblinear-82d8fcbb07d2\n",
    "\n",
    "\n",
    "    tree_method (string) – Specify which tree method to use. Default to auto. If this parameter is set to default, XGBoost will choose the most conservative option available. It’s recommended to study this option from parameters document.\n",
    "\n",
    "    n_jobs (int) – Number of parallel threads used to run xgboost. When used with other Scikit-Learn algorithms like grid search, you may choose which algorithm to parallelize and balance the threads. Creating thread contention will significantly slow dowm both algorithms.\n",
    "\n",
    "    gamma (float) – Minimum loss reduction required to make a further partition on a leaf node of the tree.\n",
    "\n",
    "    min_child_weight (float) – Minimum sum of instance weight(hessian) needed in a child.\n",
    "\n",
    "    max_delta_step (int) – Maximum delta step we allow each tree’s weight estimation to be.\n",
    "\n",
    "    subsample (float) – Subsample ratio of the training instance.\n",
    "\n",
    "    colsample_bytree (float) – Subsample ratio of columns when constructing each tree.\n",
    "\n",
    "    colsample_bylevel (float) – Subsample ratio of columns for each level.\n",
    "\n",
    "    colsample_bynode (float) – Subsample ratio of columns for each split.\n",
    "\n",
    "    reg_alpha (float (xgb's alpha)) – L1 regularization term on weights\n",
    "\n",
    "    reg_lambda (float (xgb's lambda)) – L2 regularization term on weights\n",
    "\n",
    "    scale_pos_weight (float) – Balancing of positive and negative weights.\n",
    "\n",
    "    base_score – The initial prediction score of all instances, global bias.\n",
    "\n",
    "    random_state (int) – Random number seed.\n",
    "\n",
    "\n",
    "    missing (float, default np.nan) – Value in the data which needs to be present as a missing value.\n",
    "\n",
    "    num_parallel_tree (int) – Used for boosting random forest.\n",
    "\n",
    "    monotone_constraints (str) – Constraint of variable monotonicity. See tutorial for more information.\n",
    "\n",
    "    interaction_constraints (str) – Constraints for interaction representing permitted interactions. The constraints must be specified in the form of a nest list, e.g. [[0, 1], [2, 3, 4]], where each inner list is a group of indices of features that are allowed to interact with each other. See tutorial for more information\n",
    "\n",
    "    importance_type (string, default \"gain\") – The feature importance type for the feature_importances_ property: either “gain”, “weight”, “cover”, “total_gain” or “total_cover”.\n",
    "\n",
    "Source :\n",
    "Full documentation of parameters can be found here: https://github.com/dmlc/xgboost/blob/master/doc/parameter.rst.\n",
    "\n",
    "and https://xgboost.readthedocs.io/en/latest/python/python_api.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) XGBoost model<a class=\"anchor\" id=\"XGB\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### libraries\n",
    "#from sklearn.tree import XGBClassifier\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "# Define a set of reasonable values\n",
    "#n_estimators = range(10,200,50)\n",
    "\n",
    "booster = ['gbtree', 'gblinear', 'dart']\n",
    "eta = [0.01, 0.1, 0.3]\n",
    "\n",
    "# Define a parameter grid of values\n",
    "grid = ParameterGrid({\n",
    "    'XGB__booster' : booster,\n",
    "    'XGB__eta': eta\n",
    "}\n",
    ")\n",
    " \n",
    "# Create pipeline, XGBoost classifier\n",
    "pipe = Pipeline([\n",
    "#('scaler', StandardScaler()),\n",
    "('XGB', XGBClassifier(verbosity =0\n",
    "    #scale_pos_weight=weight\n",
    "))\n",
    "])\n",
    "\n",
    "   \n",
    "# Save accuracy on test set\n",
    "test_scores = []\n",
    "\n",
    "for params_dict in grid:\n",
    "    # Set parameters\n",
    "    pipe.set_params(**params_dict)\n",
    "\n",
    "    # Fit a k-NN classifier\n",
    "    pipe.fit(X_tr, y_tr)\n",
    "\n",
    "    # Save accuracy on validation set\n",
    "    params_dict['accuracy'] = pipe.score(X_val, y_val)\n",
    "    # Save f1 score on validation set\n",
    "    # predict test instances\n",
    "    y_pred = pipe.predict(X_val)\n",
    "    params_dict['f1_macro'] = metrics.f1_score(y_val, y_pred, average='macro')\n",
    "    \n",
    "    # Save result\n",
    "    test_scores.append(params_dict)\n",
    "    \n",
    "# Create DataFrame with test scores\n",
    "scores_df = pd.DataFrame(test_scores)\n",
    "\n",
    "# Top five scores\n",
    "scores_df.sort_values(by='f1_macro', ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will try to improve the model with other parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# Define a set of reasonable values\n",
    "#n_estimators = range(10,200,50)\n",
    "\n",
    "booster = ['dart'] # 'gblinear' is removed, worst results with low score\n",
    "eta = [0.1]  # 0.01\n",
    "max_depth  = [6, 20, 50] #5, 6, 10\n",
    "subsample = [0.5, 0.85] #0.25, 0.5, 0.9\n",
    "min_child_weight =[1, 2] # 5, 10, 20\n",
    "\n",
    "# Define a parameter grid of values\n",
    "grid = ParameterGrid({\n",
    "    'XGB__booster' : booster,\n",
    "    'XGB__eta': eta,\n",
    "    'XGB__max_depth': max_depth,\n",
    "    'XGB__subsample': subsample,\n",
    "    'XGB__min_child_weight': min_child_weight\n",
    "}\n",
    ")\n",
    " \n",
    "# Create pipeline, XGBoost classifier\n",
    "pipe = Pipeline([\n",
    "#('scaler', StandardScaler()),\n",
    "('XGB', XGBClassifier(verbosity =0\n",
    "    #scale_pos_weight=weight\n",
    "))\n",
    "])\n",
    "\n",
    "   \n",
    "# Save accuracy on test set\n",
    "test_scores = []\n",
    "\n",
    "for params_dict in grid:\n",
    "    # Set parameters\n",
    "    pipe.set_params(**params_dict)\n",
    "\n",
    "    # Fit a k-NN classifier\n",
    "    pipe.fit(X_tr, y_tr)\n",
    "\n",
    "    # Save accuracy on validation set\n",
    "    params_dict['accuracy'] = pipe.score(X_val, y_val)\n",
    "    # Save f1 score on validation set\n",
    "    # predict test instances\n",
    "    y_pred = pipe.predict(X_val)\n",
    "    params_dict['f1_macro'] = metrics.f1_score(y_val, y_pred, average='macro')\n",
    "    \n",
    "    # Save result\n",
    "    test_scores.append(params_dict)\n",
    "    \n",
    "# Create DataFrame with test scores\n",
    "scores_df = pd.DataFrame(test_scores)\n",
    "\n",
    "# Top five scores\n",
    "scores_df.sort_values(by='f1_macro', ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test data with best parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I test the model with the best parameters score from the validation data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TO transform into text - made to avoid preious long steps\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "# Define a set of reasonable values\n",
    "#n_estimators = range(10,200,50)\n",
    "\n",
    " \n",
    "# Create pipeline, XGBoost classifier\n",
    "pipe = Pipeline([\n",
    "#('scaler', StandardScaler()),\n",
    "('XGB', XGBClassifier(verbosity =0\n",
    "    #scale_pos_weight=weight\n",
    "))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>XGB__booster</th>\n",
       "      <th>XGB__eta</th>\n",
       "      <th>XGB__max_depth</th>\n",
       "      <th>XGB__subsample</th>\n",
       "      <th>XGB__min_child_weight</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.3</td>\n",
       "      <td>30</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1</td>\n",
       "      <td>0.830409</td>\n",
       "      <td>0.813113</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  XGB__booster  XGB__eta  XGB__max_depth  XGB__subsample  \\\n",
       "0       gbtree       0.3              30            0.75   \n",
       "\n",
       "   XGB__min_child_weight  accuracy  f1_macro  \n",
       "0                      1  0.830409  0.813113  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### libraries\n",
    "#from sklearn.tree import XGBClassifier\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "# Define a parameter grid of values\n",
    "params_dict = {\n",
    "    'XGB__booster' : 'gbtree',\n",
    "    'XGB__eta': 0.3,\n",
    "    'XGB__max_depth': 30,\n",
    "    'XGB__subsample': 0.75,\n",
    "    'XGB__min_child_weight': 1\n",
    "}\n",
    "\n",
    " \n",
    "# Create pipeline, XGBoost classifier\n",
    "pipe = Pipeline([\n",
    "#('scaler', StandardScaler()),\n",
    "('XGB', XGBClassifier(verbosity =0\n",
    "    #scale_pos_weight=weight\n",
    "))\n",
    "])\n",
    "\n",
    "# Save accuracy on test set\n",
    "test_scores = []   \n",
    "\n",
    "pipe.set_params(**params_dict)\n",
    "\n",
    "# Fit a k-NN classifier\n",
    "pipe.fit(X_tr, y_tr)\n",
    "\n",
    "# Save accuracy on validation set\n",
    "params_dict['accuracy'] = pipe.score(X_te, y_te)\n",
    "\n",
    "# Save f1 score on test set\n",
    "# predict test instances\n",
    "y_pred = pipe.predict(X_te)\n",
    "\n",
    "params_dict['f1_macro'] = metrics.f1_score(y_te, y_pred, average='macro')\n",
    "    \n",
    "# Save result\n",
    "test_scores.append(params_dict)\n",
    "    \n",
    "# Create DataFrame with test scores\n",
    "scores_df = pd.DataFrame(test_scores)\n",
    "\n",
    "# Top five scores\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy is 93% and F1 macro is 82%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# F1_score\n",
    "XGB_F1Macro = params_dict['f1_macro']\n",
    "\n",
    "# Accuracy\n",
    "XGB_accuracy = params_dict['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_Results: [0.39028117 0.         0.         0.         0.8097167  0.81311314\n",
      " 0.         0.        ]\n",
      "Accuracy: [0.64010025 0.         0.         0.         0.82533417 0.83040936\n",
      " 0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "# Load the npz file for results\n",
    "# Specify the filename\n",
    "filename = 'Results.npz'\n",
    "\n",
    "# Combine the file path and filename\n",
    "file_path_with_filename = os.path.join(file_path, filename)\n",
    "\n",
    "# Load the npz file for results\n",
    "with np.load(file_path_with_filename, allow_pickle=False) as npz_file:\n",
    "    F1Score = npz_file['test_F1Score']\n",
    "    accuracy = npz_file['test_accuracy']\n",
    "    models = npz_file['models']\n",
    "    \n",
    "# Fill the calculated result value\n",
    "F1Score[5] = XGB_F1Macro\n",
    "accuracy[5] = XGB_accuracy\n",
    "\n",
    "print('F1_Results:', F1Score)\n",
    "print('Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify the Numpy array\n",
    "#Model = models #unchanged\n",
    "Result = F1Score\n",
    "Accuracy = accuracy\n",
    "\n",
    "# Store the changes in the results npz file\n",
    "np.savez('Results.npz', models = models, test_F1Score = Result,  test_accuracy = Accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['models', 'test_F1Score', 'test_accuracy']\n",
      "Models: ['Baseline' 'Logistic Regression' 'KNeighbors' 'Decision Tree'\n",
      " 'Random Forest' 'XGBoost' 'SelectedModel_wTickets'\n",
      " 'SelectedModel_wTickets&Telemetry']\n",
      "F1_Results: [0.39028117 0.         0.         0.         0.8097167  0.81311314\n",
      " 0.         0.        ]\n",
      "Accuracy: [0.64010025 0.         0.         0.         0.82533417 0.83040936\n",
      " 0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "# Check the refreshed results\n",
    "# Load the npz file for results\n",
    "with np.load('Results.npz', allow_pickle=False) as npz_file:\n",
    "    # It's a dictionary-like object    \n",
    "    print(list(npz_file.keys()))\n",
    "    # Load the arrays\n",
    "    print('Models:', npz_file['models'])\n",
    "    print('F1_Results:', npz_file['test_F1Score'])\n",
    "    print('Accuracy:', npz_file['test_accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[27163  3485]\n",
      " [ 4635 12597]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False      0.854     0.886     0.870     30648\n",
      "        True      0.783     0.731     0.756     17232\n",
      "\n",
      "    accuracy                          0.830     47880\n",
      "   macro avg      0.819     0.809     0.813     47880\n",
      "weighted avg      0.829     0.830     0.829     47880\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Classification reports and confusion matrices are commonly used for reporting the performance of classifiers when working with imbalanced datasets.\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(metrics.confusion_matrix(y_te, y_pred))\n",
    "\n",
    "# Print the precision and recall, among other metrics\n",
    "print(metrics.classification_report(y_te, y_pred, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>False Condition</th>\n",
       "      <th>True Condition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Predicted False</th>\n",
       "      <td>27163</td>\n",
       "      <td>4635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predicted True</th>\n",
       "      <td>3485</td>\n",
       "      <td>12597</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 False Condition  True Condition\n",
       "Predicted False            27163            4635\n",
       "Predicted True              3485           12597"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Classification reports and confusion matrices are commonly used for reporting the performance of classifiers when working with imbalanced datasets.\n",
    "ConfMat_df = pd.DataFrame(metrics.confusion_matrix(y_te, y_pred).T, columns=['False Condition', 'True Condition'],index=['Predicted False', 'Predicted True'])\n",
    "ConfMat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the filename\n",
    "filename = 'XGBoost_ConfMat_df.p'\n",
    "\n",
    "# Combine the file path and filename\n",
    "file_path_with_filename = os.path.join(file_path, filename)\n",
    "\n",
    "# Save the DataFrame into a pickle file\n",
    "with open(file_path_with_filename, 'wb') as file:\n",
    "    pickle.dump(ConfMat_df, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction of churn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Need the one in the same format, so with removed Sales Org\n",
    "# Load the pickle file\n",
    "with open('BM_noTicketsWOSO.p', 'rb') as file:\n",
    "    BM_noTicketsWOSO = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the filename\n",
    "filename = 'BeverageMachine_withSerial.p'\n",
    "\n",
    "# Combine the file path and filename\n",
    "file_path_with_filename = os.path.join(file_path, filename)\n",
    "\n",
    "# Load the pickle file\n",
    "with open(file_path_with_filename, 'rb') as file:\n",
    "    BeverageMachine_withSerial = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>False</th>\n",
       "      <th>True</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Serial ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>153933605</th>\n",
       "      <td>0.955170</td>\n",
       "      <td>0.044830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160708192</th>\n",
       "      <td>0.986454</td>\n",
       "      <td>0.013546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160708189</th>\n",
       "      <td>0.712961</td>\n",
       "      <td>0.287039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153933611</th>\n",
       "      <td>0.896588</td>\n",
       "      <td>0.103412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153933610</th>\n",
       "      <td>0.871160</td>\n",
       "      <td>0.128840</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              False      True\n",
       "Serial ID                    \n",
       "153933605  0.955170  0.044830\n",
       "160708192  0.986454  0.013546\n",
       "160708189  0.712961  0.287039\n",
       "153933611  0.896588  0.103412\n",
       "153933610  0.871160  0.128840"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name = ['False', 'True']\n",
    "No=BeverageMachine_withSerial['Serial ID']\n",
    "predictions = pipe.predict_proba(X)\n",
    "# With two column indices, values same  \n",
    "# as dictionary keys \n",
    "df2 = pd.DataFrame(predictions, index=No ,columns = name) \n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial ID</th>\n",
       "      <th>False</th>\n",
       "      <th>True</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>153933605</td>\n",
       "      <td>0.955170</td>\n",
       "      <td>0.044830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>160708192</td>\n",
       "      <td>0.986454</td>\n",
       "      <td>0.013546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>160708189</td>\n",
       "      <td>0.712961</td>\n",
       "      <td>0.287039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>153933611</td>\n",
       "      <td>0.896588</td>\n",
       "      <td>0.103412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>153933610</td>\n",
       "      <td>0.871160</td>\n",
       "      <td>0.128840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239395</th>\n",
       "      <td>20O0017858</td>\n",
       "      <td>0.000135</td>\n",
       "      <td>0.999865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239396</th>\n",
       "      <td>20O0017859</td>\n",
       "      <td>0.000179</td>\n",
       "      <td>0.999821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239397</th>\n",
       "      <td>20O0017862</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>0.999893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239398</th>\n",
       "      <td>20O0017861</td>\n",
       "      <td>0.000221</td>\n",
       "      <td>0.999779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239399</th>\n",
       "      <td>20O0017860</td>\n",
       "      <td>0.003155</td>\n",
       "      <td>0.996845</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>239400 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Serial ID     False      True\n",
       "0        153933605  0.955170  0.044830\n",
       "1        160708192  0.986454  0.013546\n",
       "2        160708189  0.712961  0.287039\n",
       "3        153933611  0.896588  0.103412\n",
       "4        153933610  0.871160  0.128840\n",
       "...            ...       ...       ...\n",
       "239395  20O0017858  0.000135  0.999865\n",
       "239396  20O0017859  0.000179  0.999821\n",
       "239397  20O0017862  0.000107  0.999893\n",
       "239398  20O0017861  0.000221  0.999779\n",
       "239399  20O0017860  0.003155  0.996845\n",
       "\n",
       "[239400 rows x 3 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3 = df2.reset_index(level=None)\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 239400 entries, 0 to 239399\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count   Dtype  \n",
      "---  ------     --------------   -----  \n",
      " 0   index      239400 non-null  int64  \n",
      " 1   Serial ID  239400 non-null  object \n",
      " 2   False      239400 non-null  float32\n",
      " 3   True       239400 non-null  float32\n",
      "dtypes: float32(2), int64(1), object(1)\n",
      "memory usage: 5.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df3.reset_index(inplace=True)\n",
    "df3.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df21 = pd.DataFrame(BeverageMachine_withSerial[['Serial ID','Churn']]).reset_index(level=None)\n",
    "df21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Serial ID</th>\n",
       "      <th>Churn</th>\n",
       "      <th>Sales Organisation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>153933605</td>\n",
       "      <td>False</td>\n",
       "      <td>Néstlé Jordania</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>160708192</td>\n",
       "      <td>False</td>\n",
       "      <td>Néstlé Jordania</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>160708189</td>\n",
       "      <td>False</td>\n",
       "      <td>Néstlé Jordania</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>153933611</td>\n",
       "      <td>False</td>\n",
       "      <td>Néstlé Jordania</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>153933610</td>\n",
       "      <td>False</td>\n",
       "      <td>Néstlé Jordania</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239395</th>\n",
       "      <td>239395</td>\n",
       "      <td>20O0017858</td>\n",
       "      <td>True</td>\n",
       "      <td>Singapore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239396</th>\n",
       "      <td>239396</td>\n",
       "      <td>20O0017859</td>\n",
       "      <td>True</td>\n",
       "      <td>Singapore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239397</th>\n",
       "      <td>239397</td>\n",
       "      <td>20O0017862</td>\n",
       "      <td>True</td>\n",
       "      <td>Singapore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239398</th>\n",
       "      <td>239398</td>\n",
       "      <td>20O0017861</td>\n",
       "      <td>True</td>\n",
       "      <td>Singapore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239399</th>\n",
       "      <td>239399</td>\n",
       "      <td>20O0017860</td>\n",
       "      <td>True</td>\n",
       "      <td>Singapore</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>239400 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         index   Serial ID  Churn Sales Organisation\n",
       "0            0   153933605  False    Néstlé Jordania\n",
       "1            1   160708192  False    Néstlé Jordania\n",
       "2            2   160708189  False    Néstlé Jordania\n",
       "3            3   153933611  False    Néstlé Jordania\n",
       "4            4   153933610  False    Néstlé Jordania\n",
       "...        ...         ...    ...                ...\n",
       "239395  239395  20O0017858   True          Singapore\n",
       "239396  239396  20O0017859   True          Singapore\n",
       "239397  239397  20O0017862   True          Singapore\n",
       "239398  239398  20O0017861   True          Singapore\n",
       "239399  239399  20O0017860   True          Singapore\n",
       "\n",
       "[239400 rows x 4 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df21 = pd.DataFrame(BeverageMachine_withSerial[['Serial ID','Churn', 'Sales Organisation']]).reset_index(level=None)\n",
    "df21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 239400 entries, 0 to 239399\n",
      "Data columns (total 4 columns):\n",
      " #   Column              Non-Null Count   Dtype \n",
      "---  ------              --------------   ----- \n",
      " 0   index               239400 non-null  int64 \n",
      " 1   Serial ID           239400 non-null  object\n",
      " 2   Churn               239400 non-null  bool  \n",
      " 3   Sales Organisation  239400 non-null  object\n",
      "dtypes: bool(1), int64(1), object(2)\n",
      "memory usage: 5.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df21.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3['Serial ID'] = df3['Serial ID'].astype('str')\n",
    "df21['Serial ID'] = df21['Serial ID'].astype('str')\n",
    "df3['index'] = df3['index'].astype('str')\n",
    "df21['index'] = df21['index'].astype('str')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3['KeyIndSer'] = df3['index'] + \"-\" + df3['Serial ID']\n",
    "df21['KeyIndSer'] = df21['index'] + \"-\" + df21['Serial ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = pd.merge(df3, df21, how='left', left_on = ['KeyIndSer'], right_on = ['KeyIndSer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 239400 entries, 0 to 239399\n",
      "Data columns (total 9 columns):\n",
      " #   Column              Non-Null Count   Dtype  \n",
      "---  ------              --------------   -----  \n",
      " 0   index_x             239400 non-null  object \n",
      " 1   Serial ID_x         239400 non-null  object \n",
      " 2   False               239400 non-null  float32\n",
      " 3   True                239400 non-null  float32\n",
      " 4   KeyIndSer           239400 non-null  object \n",
      " 5   index_y             239400 non-null  object \n",
      " 6   Serial ID_y         239400 non-null  object \n",
      " 7   Churn               239400 non-null  bool   \n",
      " 8   Sales Organisation  239400 non-null  object \n",
      "dtypes: bool(1), float32(2), object(6)\n",
      "memory usage: 14.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df4.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.to_csv(r'C:\\Users\\msalomo\\predictions-Churn-XGBOOST.csv', index = False, header=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forests generally outperform decision trees, but their accuracy is lower than gradient boosted trees. But in the end I might still use Decision Tree or Random Forest because the score is not based on the accuracy but on the F1_macro score. Here in this case the best model is Random Forest."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
