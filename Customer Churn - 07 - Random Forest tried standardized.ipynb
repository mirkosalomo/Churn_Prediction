{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone proposal by Mirko Salomon \n",
    "\n",
    "# BEVERAGE MACHINE CHURN PREDICTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ## [1) Introduction and preparation](#Introduction) \n",
    "\n",
    "    *   \n",
    "        #### Data Load\n",
    "        \n",
    "        #### Hyperparameters\n",
    "        \n",
    "* ## [2) Random Forest model](#RF)\n",
    "    \n",
    "    *   \n",
    "        #### Train the model\n",
    "        \n",
    "        #### Test data with best parameters \n",
    "        \n",
    "        #### Confusion Matrix\n",
    "        \n",
    "        #### Tree Plot\n",
    "        \n",
    "        #### Prediction of churn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Introduction and preparation<a class=\"anchor\" id=\"Introduction\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forests are an ensemble learning method for classification that operate by constructing a multitude of decision trees at training time and outputting the class that is the mode of the classes (classification) or mean/average prediction (regression) of the individual trees.\n",
    "\n",
    "Based on the flowchart from Scikit Learn I should try a Random Forest model.\n",
    "\n",
    "This model is a bit more a black box than a regression or decision tree\n",
    "\n",
    "Has predict_proba that predicts class probabilities for X, can handle well categorical features, maintains accuracy when the data is missing\n",
    "\n",
    "Seems to have good Performance on Imbalanced datasets and we can also modify the weights\n",
    "\n",
    "Is a model working differently than a regression model and performs usually better than a decision tree\n",
    "\n",
    "I will tune the number of estimators and the maximum number of features. I will also tune the class weigth and the bootstrap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pickle\n",
    "\n",
    "import xlrd\n",
    "\n",
    "import datetime as dt\n",
    "from datetime import datetime\n",
    "\n",
    "import collections\n",
    "from collections import Counter\n",
    "\n",
    "# Import seaborn\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conda update -c conda-forge scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install --upgrade scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#libraries\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Import Random Forest Model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "from sklearn import metrics \n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#from sklearn.metrics import plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pickle file\n",
    "with open('BM_noTickets_preprocess.p', 'rb') as file:\n",
    "    BM_noTickets_preprocess = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pickle file\n",
    "with open('X.p', 'rb') as file:\n",
    "    X = pickle.load(file)\n",
    "\n",
    "# Load the pickle file\n",
    "with open('y.p', 'rb') as file:\n",
    "    y = pickle.load(file)\n",
    "\n",
    "# Load the pickle file\n",
    "with open('X_tr.p', 'rb') as file:\n",
    "    X_tr = pickle.load(file)\n",
    "\n",
    "# Load the pickle file\n",
    "with open('y_tr.p', 'rb') as file:\n",
    "    y_tr = pickle.load(file)\n",
    "\n",
    "# Load the pickle file\n",
    "with open('X_val.p', 'rb') as file:\n",
    "    X_val = pickle.load(file)\n",
    "\n",
    "# Load the pickle file\n",
    "with open('y_val.p', 'rb') as file:\n",
    "    y_val = pickle.load(file)\n",
    "\n",
    "# Load the pickle file\n",
    "with open('X_te.p', 'rb') as file:\n",
    "    X_te = pickle.load(file)\n",
    "\n",
    "# Load the pickle file\n",
    "with open('y_te.p', 'rb') as file:\n",
    "    y_te = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TA Contract Installation Date</th>\n",
       "      <th>Depreciation Start</th>\n",
       "      <th>TA Contract Start Date</th>\n",
       "      <th>TA Contract End Date</th>\n",
       "      <th>Churn</th>\n",
       "      <th>Service Category_Installation</th>\n",
       "      <th>Service Category_Removal</th>\n",
       "      <th>Service Category_Replacement</th>\n",
       "      <th>INCIDENT_CATEGORY_DESCRIPTION_Customer relocation</th>\n",
       "      <th>INCIDENT_CATEGORY_DESCRIPTION_Exchange / Replacement Sales</th>\n",
       "      <th>...</th>\n",
       "      <th>Generation_Gen. 2</th>\n",
       "      <th>Generation_Legacy</th>\n",
       "      <th>Blueprint Throughput_%23-N/A</th>\n",
       "      <th>Blueprint Throughput_High</th>\n",
       "      <th>Blueprint Throughput_Low</th>\n",
       "      <th>Blueprint Throughput_Medium</th>\n",
       "      <th>IP Ownership_Exclusive</th>\n",
       "      <th>IP Ownership_Non-Proprietary</th>\n",
       "      <th>IP Ownership_Propr. Comp.</th>\n",
       "      <th>IP Ownership_Proprietary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1751.0</td>\n",
       "      <td>2716.0</td>\n",
       "      <td>1744.0</td>\n",
       "      <td>103.19015</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1751.0</td>\n",
       "      <td>485.0</td>\n",
       "      <td>1744.0</td>\n",
       "      <td>103.19015</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1751.0</td>\n",
       "      <td>2191.0</td>\n",
       "      <td>1744.0</td>\n",
       "      <td>103.19015</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1751.0</td>\n",
       "      <td>2191.0</td>\n",
       "      <td>1744.0</td>\n",
       "      <td>103.19015</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1751.0</td>\n",
       "      <td>2191.0</td>\n",
       "      <td>1744.0</td>\n",
       "      <td>103.19015</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1350 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   TA Contract Installation Date  Depreciation Start  TA Contract Start Date  \\\n",
       "0                         1751.0              2716.0                  1744.0   \n",
       "1                         1751.0               485.0                  1744.0   \n",
       "2                         1751.0              2191.0                  1744.0   \n",
       "3                         1751.0              2191.0                  1744.0   \n",
       "4                         1751.0              2191.0                  1744.0   \n",
       "\n",
       "   TA Contract End Date  Churn  Service Category_Installation  \\\n",
       "0             103.19015  False                            0.0   \n",
       "1             103.19015  False                            1.0   \n",
       "2             103.19015  False                            1.0   \n",
       "3             103.19015  False                            1.0   \n",
       "4             103.19015  False                            1.0   \n",
       "\n",
       "   Service Category_Removal  Service Category_Replacement  \\\n",
       "0                       0.0                           3.0   \n",
       "1                       0.0                           0.0   \n",
       "2                       0.0                           0.0   \n",
       "3                       0.0                           0.0   \n",
       "4                       0.0                           0.0   \n",
       "\n",
       "   INCIDENT_CATEGORY_DESCRIPTION_Customer relocation  \\\n",
       "0                                                0.0   \n",
       "1                                                0.0   \n",
       "2                                                0.0   \n",
       "3                                                0.0   \n",
       "4                                                0.0   \n",
       "\n",
       "   INCIDENT_CATEGORY_DESCRIPTION_Exchange / Replacement Sales  ...  \\\n",
       "0                                                1.0           ...   \n",
       "1                                                0.0           ...   \n",
       "2                                                0.0           ...   \n",
       "3                                                0.0           ...   \n",
       "4                                                0.0           ...   \n",
       "\n",
       "   Generation_Gen. 2  Generation_Legacy  Blueprint Throughput_%23-N/A  \\\n",
       "0                  1                  0                             0   \n",
       "1                  0                  1                             1   \n",
       "2                  0                  1                             0   \n",
       "3                  0                  1                             0   \n",
       "4                  0                  1                             0   \n",
       "\n",
       "   Blueprint Throughput_High  Blueprint Throughput_Low  \\\n",
       "0                          0                         0   \n",
       "1                          0                         0   \n",
       "2                          0                         1   \n",
       "3                          0                         1   \n",
       "4                          0                         1   \n",
       "\n",
       "   Blueprint Throughput_Medium  IP Ownership_Exclusive  \\\n",
       "0                            1                       0   \n",
       "1                            0                       0   \n",
       "2                            0                       0   \n",
       "3                            0                       0   \n",
       "4                            0                       0   \n",
       "\n",
       "   IP Ownership_Non-Proprietary  IP Ownership_Propr. Comp.  \\\n",
       "0                             1                          0   \n",
       "1                             1                          0   \n",
       "2                             1                          0   \n",
       "3                             1                          0   \n",
       "4                             1                          0   \n",
       "\n",
       "   IP Ownership_Proprietary  \n",
       "0                         0  \n",
       "1                         0  \n",
       "2                         0  \n",
       "3                         0  \n",
       "4                         0  \n",
       "\n",
       "[5 rows x 1350 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BM_noTickets_preprocess.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 230786 entries, 0 to 230785\n",
      "Columns: 1350 entries, TA Contract Installation Date to IP Ownership_Proprietary\n",
      "dtypes: bool(1), float64(103), int32(2), int64(2), object(1), uint8(1241)\n",
      "memory usage: 463.5+ MB\n"
     ]
    }
   ],
   "source": [
    "BM_noTickets_preprocess.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class sklearn.ensemble.RandomForestClassifier(n_estimators=100, *, criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='auto', max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, bootstrap=True, oob_score=False, n_jobs=None, random_state=None, verbose=0, warm_start=False, class_weight=None, ccp_alpha=0.0, max_samples=None)\n",
    "\n",
    "---\n",
    "\n",
    "The number of trees in the forest. I will try some.\n",
    "\n",
    "n_estimators = range(20,200,20)\n",
    "\n",
    "---\n",
    "\n",
    "The maximum depth of the tree. I will try some.\n",
    "\n",
    "max_depth = (20, 50, 100, None)\n",
    "\n",
    "---\n",
    "\n",
    "The function to measure the quality of a split. I will try both.\n",
    "\n",
    "criterion = ('gini', 'entropy')\n",
    "\n",
    "---\n",
    "\n",
    "Whether bootstrap samples are used when building trees. If False, the whole dataset is used to build each tree.\n",
    "I will try both.\n",
    "\n",
    "bootstrap = (True, False)\n",
    "\n",
    "---\n",
    "\n",
    "Weights associated with classes in the form.\n",
    "\n",
    "class_weight = ('balanced', None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Random Forest model<a class=\"anchor\" id=\"RF\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(129239,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(129239, 1349)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46158, 1349)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(X_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 39\u001b[0m\n\u001b[0;32m     36\u001b[0m pipe\u001b[38;5;241m.\u001b[39mset_params(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams_dict)\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# Fit a k-NN classifier\u001b[39;00m\n\u001b[1;32m---> 39\u001b[0m \u001b[43mpipe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_tr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_tr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# Save accuracy on validation set\u001b[39;00m\n\u001b[0;32m     42\u001b[0m params_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pipe\u001b[38;5;241m.\u001b[39mscore(X_val, y_val)\n",
      "File \u001b[1;32mc:\\miniconda3\\lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\miniconda3\\lib\\site-packages\\sklearn\\pipeline.py:420\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    418\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    419\u001b[0m         fit_params_last_step \u001b[38;5;241m=\u001b[39m fit_params_steps[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]]\n\u001b[1;32m--> 420\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator\u001b[38;5;241m.\u001b[39mfit(Xt, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params_last_step)\n\u001b[0;32m    422\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\miniconda3\\lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:456\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    445\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    446\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[0;32m    447\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[0;32m    448\u001b[0m ]\n\u001b[0;32m    450\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[0;32m    451\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[0;32m    453\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[0;32m    454\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[0;32m    455\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m--> 456\u001b[0m trees \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    458\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    459\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    460\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    461\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    462\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    463\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    464\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    465\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    466\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    467\u001b[0m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    468\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    469\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    470\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    471\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    472\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    473\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    474\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    476\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[0;32m    477\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[1;32mc:\\miniconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\miniconda3\\lib\\site-packages\\joblib\\parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1085\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1088\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1089\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m   1091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1092\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1093\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1094\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\miniconda3\\lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\miniconda3\\lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32mc:\\miniconda3\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m     \u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32mc:\\miniconda3\\lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\miniconda3\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\miniconda3\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\miniconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    125\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:190\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[0;32m    188\u001b[0m     tree\u001b[38;5;241m.\u001b[39mfit(X, y, sample_weight\u001b[38;5;241m=\u001b[39mcurr_sample_weight, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 190\u001b[0m     \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    192\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tree\n",
      "File \u001b[1;32mc:\\miniconda3\\lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\miniconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:959\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    928\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    929\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m    930\u001b[0m     \u001b[38;5;124;03m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[0;32m    931\u001b[0m \n\u001b[0;32m    932\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    956\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m    957\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 959\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    960\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    961\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    962\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    963\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    964\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    965\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\miniconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:443\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[1;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    432\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    433\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    434\u001b[0m         splitter,\n\u001b[0;32m    435\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    440\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    441\u001b[0m     )\n\u001b[1;32m--> 443\u001b[0m \u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    445\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    446\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Define a set of reasonable values\n",
    "#n_estimators = range(20,160,20) # I tried till 200 but it was not in the top results, so I reduced to 160\n",
    "n_estimators = range(20,120,60) # I tried till 200 but it was not in the top results, so I reduced to 160\n",
    "\n",
    "#max_depth = (20, 50, 10, None) # I tried with 200, 300, but results were not better\n",
    "max_depth = (20, 50, None) # I tried with 200, 300, but results were not better\n",
    "\n",
    "criterion = ('gini', 'entropy')\n",
    "#bootstrap = (True, False)\n",
    "bootstrap = (True)\n",
    "class_weight = ('balanced', None) # I tried with  'balanced_subsample', but I had lower scores.\n",
    "\n",
    "\n",
    "# Define a parameter grid of values\n",
    "grid = ParameterGrid({'rf__n_estimators' : n_estimators,\n",
    "                    'rf__max_depth' : max_depth,\n",
    "                    'rf__criterion' :  criterion,\n",
    "                    'rf__bootstrap' : (True, False),\n",
    "                    'rf__class_weight' : class_weight \n",
    "                   }\n",
    "                  )\n",
    " \n",
    "\n",
    "# Create pipeline, random forest classifier\n",
    "pipe = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('rf', RandomForestClassifier(random_state=1))\n",
    "    ]\n",
    ")\n",
    "   \n",
    "# Save accuracy on test set\n",
    "test_scores = []\n",
    "\n",
    "for params_dict in grid:\n",
    "    # Set parameters\n",
    "    pipe.set_params(**params_dict)\n",
    "\n",
    "    # Fit a k-NN classifier\n",
    "    pipe.fit(X_tr, y_tr)\n",
    "\n",
    "    # Save accuracy on validation set\n",
    "    params_dict['accuracy'] = pipe.score(X_val, y_val)\n",
    "    # Save f1 score on validation set\n",
    "    # predict test instances\n",
    "    y_pred = pipe.predict(X_val)\n",
    "    params_dict['f1_macro'] = metrics.f1_score(y_val, y_pred, average='macro')\n",
    "    \n",
    "    # Save result\n",
    "    test_scores.append(params_dict)\n",
    "    \n",
    "# Create DataFrame with test scores\n",
    "scores_df = pd.DataFrame(test_scores)\n",
    "\n",
    "# Top five scores\n",
    "scores_df.sort_values(by='f1_macro', ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "rf = RandomForestClassifier(random_state=1)\n",
    "rf.fit(X_tr, y_tr)\n",
    "y_pred = rf.predict(X_te) # Predictions\n",
    "y_true = y_te # True values\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Train accuracy:\", np.round(accuracy_score(y_tr, \n",
    "                                                 rfc.predict(X_tr)), 2))\n",
    "print(\"Test accuracy:\", np.round(accuracy_score(y_true, y_pred), 2))\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cf_matrix = confusion_matrix(y_true, y_pred)\n",
    "print(\"\\nTest confusion_matrix\")\n",
    "sns.heatmap(cf_matrix, annot=True, cmap='Blues')\n",
    "plt.xlabel('Predicted', fontsize=12)\n",
    "plt.ylabel('True', fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "estimator.get_params().keys()\n",
    "param = {'rf__n_estimators' : n_estimators,\n",
    "         'rf__max_depth' : max_depth,\n",
    "         'rf__criterion' :  criterion,\n",
    "         'rf__bootstrap' : (True, False),\n",
    "         'rf__class_weight' : class_weight \n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's measure execution time too\n",
    "import time\n",
    "start = time.time()\n",
    "\n",
    "# Define a set of reasonable values\n",
    "n_estimators = range(20,160,20) # I tried till 200 but it was not in the top results, so I reduced to 160\n",
    "max_depth = (20, 50, 10, None) # I tried with 200, 300, but results were not better\n",
    "criterion = ('gini', 'entropy')\n",
    "bootstrap = (True, False)\n",
    "class_weight = ('balanced', None) # I tried with  'balanced_subsample', but I had lower scores.\n",
    "\n",
    "\n",
    "# Defining 3-dimensional hyperparameter space as a Python dictionary\n",
    "#hyperparameter_space = {'rf__n_estimators' : n_estimators, 'rf__max_depth' : max_depth,\n",
    "#                    'rf__criterion' :  criterion,\n",
    "#                    'rf__bootstrap' : (True, False),\n",
    "#                    'rf__class_weight' : class_weight \n",
    "\n",
    "#param = {'rf__n_estimators' : n_estimators,\n",
    "#         'rf__max_depth' : max_depth,\n",
    "#         'rf__max_depth' : max_depth,\n",
    "#         'rf__criterion' :  criterion,\n",
    "#         'rf__bootstrap' : (True, False),\n",
    "#         'rf__class_weight' : class_weight \n",
    "#        }\n",
    "\n",
    "random_grid = {'bootstrap': [True, False],\n",
    "               'max_depth': [10, None],\n",
    "               'min_samples_leaf': [1, 4],\n",
    "               'min_samples_split': [2, 5],\n",
    "               'n_estimators': [130, 230]}\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "#rs = RandomizedSearchCV(rfc, param_distributions=hyperparameter_space,\n",
    "#                        n_iter=10, scoring= 'f1_macro', random_state=1,\n",
    "#                        n_jobs=-1, cv=10, return_train_score=True)\n",
    "\n",
    "\n",
    "#rs = RandomizedSearchCV(rf, param, n_iter =10, cv=9)\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, verbose=2, random_state=42, n_jobs = -1)\n",
    "\n",
    "rf_random.fit(X_tr, y_tr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#rs.fit(X_tr, y_tr)\n",
    "print(\"Optimal hyperparameter combination:\", rs.best_params_)\n",
    "print()\n",
    "print(\"Mean cross-validated training accuracy score:\",\n",
    "      rs.best_score_)\n",
    "rs.best_estimator_.fit(X_tr, y_tr)\n",
    "y_pred = rs.best_estimator_.predict(X_te) # Predictions\n",
    "y_true = y_te # True values\n",
    "\n",
    "print(\"Test accuracy:\", np.round(accuracy_score(y_true, y_pred), 2))\n",
    "cf_matrix = confusion_matrix(y_true, y_pred)\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.heatmap(cf_matrix, annot=True, cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "\n",
    "end = time.time()\n",
    "diff = end - start\n",
    "print('Execution time of Random Search (in Seconds):', diff)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cv_results = rf_random.cv_results_\n",
    "for mean_score, params in zip(cv_results[\"mean_test_score\"], cvres[\"params\"]):\n",
    "    print(np.sqrt(-mean_score), params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rf__n_estimators</th>\n",
       "      <th>rf__max_depth</th>\n",
       "      <th>rf__criterion</th>\n",
       "      <th>rf__bootstrap</th>\n",
       "      <th>rf__class_weight</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>80</td>\n",
       "      <td>50</td>\n",
       "      <td>entropy</td>\n",
       "      <td>False</td>\n",
       "      <td>balanced</td>\n",
       "      <td>0.818991</td>\n",
       "      <td>0.797082</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rf__n_estimators  rf__max_depth rf__criterion  rf__bootstrap  \\\n",
       "0                80             50       entropy          False   \n",
       "\n",
       "  rf__class_weight  accuracy  f1_macro  \n",
       "0         balanced  0.818991  0.797082  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_dict = {'rf__n_estimators': 80, \n",
    " 'rf__max_depth': 50, \n",
    " 'rf__criterion': 'entropy', \n",
    " 'rf__bootstrap': False, \n",
    " 'rf__class_weight': 'balanced'}\n",
    "\n",
    "# Create pipeline, random forest classifier\n",
    "pipe = Pipeline([\n",
    "    #('oversample', SmoteSample_model),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('rf', RandomForestClassifier(random_state=1))\n",
    "    ]\n",
    ")\n",
    "  \n",
    "# Save accuracy on test set\n",
    "test_scores = []\n",
    "\n",
    "# Set parameters\n",
    "pipe.set_params(**params_dict)\n",
    "\n",
    "# Fit a k-NN classifier\n",
    "pipe.fit(X_tr, y_tr)\n",
    "\n",
    "# Save accuracy on validation set\n",
    "params_dict['accuracy'] = pipe.score(X_te, y_te)\n",
    "# Save f1 score on validation set\n",
    "# predict test instances\n",
    "y_pred = pipe.predict(X_te)\n",
    "params_dict['f1_macro'] = metrics.f1_score(y_te, y_pred, average='macro')\n",
    "    \n",
    "# Save result\n",
    "test_scores.append(params_dict)\n",
    "    \n",
    "# Create DataFrame with test scores\n",
    "scores_df = pd.DataFrame(test_scores)\n",
    "\n",
    "# Top five scores\n",
    "scores_df.sort_values(by='f1_macro', ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have an F1 Macro score of 83.8% and an accuracy of 93.7% with the test data. Which is close to the validation data results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# F1_score\n",
    "RF_F1Macro = params_dict['f1_macro']\n",
    "\n",
    "# Accuracy\n",
    "RF_accuracy = params_dict['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_Results: [0.39728138 0.         0.         0.         0.79708213 0.\n",
      " 0.         0.        ]\n",
      "Accuracy: [0.65914901 0.         0.         0.         0.81899129 0.\n",
      " 0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "# Load the npz file for results\n",
    "with np.load('Results.npz', allow_pickle=False) as npz_file:\n",
    "    F1Score = npz_file['test_F1Score']\n",
    "    accuracy = npz_file['test_accuracy']\n",
    "    models = npz_file['models']\n",
    "    \n",
    "# Fill the calculated result value\n",
    "F1Score[4] = RF_F1Macro\n",
    "accuracy[4] = RF_accuracy\n",
    "\n",
    "print('F1_Results:', F1Score)\n",
    "print('Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify the Numpy array\n",
    "#Model = models #unchanged\n",
    "Result = F1Score\n",
    "Accuracy = accuracy\n",
    "\n",
    "# Store the changes in the results npz file\n",
    "np.savez('Results.npz', models = models, test_F1Score = Result,  test_accuracy = Accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['models', 'test_F1Score', 'test_accuracy']\n",
      "Models: ['Baseline' 'Logistic Regression' 'KNeighbors' 'Decision Tree'\n",
      " 'Random Forest' 'XGBoost' 'SelectedModel_wTickets'\n",
      " 'SelectedModel_wTickets&Telemetry']\n",
      "F1_Results: [0.39728138 0.         0.         0.         0.79708213 0.\n",
      " 0.         0.        ]\n",
      "Accuracy: [0.65914901 0.         0.         0.         0.81899129 0.\n",
      " 0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "# Check the refreshed results\n",
    "# Load the npz file for results\n",
    "with np.load('Results.npz', allow_pickle=False) as npz_file:\n",
    "    # It's a dictionary-like object    \n",
    "    print(list(npz_file.keys()))\n",
    "    # Load the arrays\n",
    "    print('Models:', npz_file['models'])\n",
    "    print('F1_Results:', npz_file['test_F1Score'])\n",
    "    print('Accuracy:', npz_file['test_accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[26485  3940]\n",
      " [ 4415 11318]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False      0.857     0.871     0.864     30425\n",
      "        True      0.742     0.719     0.730     15733\n",
      "\n",
      "    accuracy                          0.819     46158\n",
      "   macro avg      0.799     0.795     0.797     46158\n",
      "weighted avg      0.818     0.819     0.818     46158\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Classification reports and confusion matrices are commonly used for reporting the performance of classifiers when working with imbalanced datasets.\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(metrics.confusion_matrix(y_te, y_pred))\n",
    "\n",
    "# Print the precision and recall, among other metrics\n",
    "print(metrics.classification_report(y_te, y_pred, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>False Condition</th>\n",
       "      <th>True Condition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Predicted False</th>\n",
       "      <td>26485</td>\n",
       "      <td>4415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predicted True</th>\n",
       "      <td>3940</td>\n",
       "      <td>11318</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 False Condition  True Condition\n",
       "Predicted False            26485            4415\n",
       "Predicted True              3940           11318"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Classification reports and confusion matrices are commonly used for reporting the performance of classifiers when working with imbalanced datasets.\n",
    "ConfMat_df = pd.DataFrame(metrics.confusion_matrix(y_te, y_pred).T, columns=['False Condition', 'True Condition'],index=['Predicted False', 'Predicted True'])\n",
    "ConfMat_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a good F1 Score for the False Condition but not as good for the True Condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the Dataframe into a pickle file\n",
    "with open('Random Forest_ConfMat_df.p', 'wb') as file:\n",
    "    pickle.dump(ConfMat_df, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction of churn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Churn prediction from the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need the one in the same format, so with removed Sales Org\n",
    "# Load the pickle file\n",
    "with open('BeverageMachine_withSerial.p', 'rb') as file:\n",
    "    BeverageMachine_withSerial = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "name = ['False', 'True']\n",
    "No=BeverageMachine_withSerial['Serial ID']\n",
    "predictions = pipe.predict_proba(X)\n",
    "# With two column indices, values same  \n",
    "# as dictionary keys \n",
    "df2 = pd.DataFrame(predictions, index=No ,columns = name) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial ID</th>\n",
       "      <th>False</th>\n",
       "      <th>True</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MYBMB25820</td>\n",
       "      <td>0.858197</td>\n",
       "      <td>0.141803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22O0025413</td>\n",
       "      <td>0.955200</td>\n",
       "      <td>0.044800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22O0023817</td>\n",
       "      <td>0.601167</td>\n",
       "      <td>0.398833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22O0023735</td>\n",
       "      <td>0.695519</td>\n",
       "      <td>0.304481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22O0023729</td>\n",
       "      <td>0.640347</td>\n",
       "      <td>0.359653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230781</th>\n",
       "      <td>20O0017858</td>\n",
       "      <td>0.021987</td>\n",
       "      <td>0.978013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230782</th>\n",
       "      <td>20O0017859</td>\n",
       "      <td>0.006570</td>\n",
       "      <td>0.993430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230783</th>\n",
       "      <td>20O0017862</td>\n",
       "      <td>0.091315</td>\n",
       "      <td>0.908685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230784</th>\n",
       "      <td>20O0017861</td>\n",
       "      <td>0.066315</td>\n",
       "      <td>0.933685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230785</th>\n",
       "      <td>20O0017860</td>\n",
       "      <td>0.153807</td>\n",
       "      <td>0.846193</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>230786 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Serial ID     False      True\n",
       "0       MYBMB25820  0.858197  0.141803\n",
       "1       22O0025413  0.955200  0.044800\n",
       "2       22O0023817  0.601167  0.398833\n",
       "3       22O0023735  0.695519  0.304481\n",
       "4       22O0023729  0.640347  0.359653\n",
       "...            ...       ...       ...\n",
       "230781  20O0017858  0.021987  0.978013\n",
       "230782  20O0017859  0.006570  0.993430\n",
       "230783  20O0017862  0.091315  0.908685\n",
       "230784  20O0017861  0.066315  0.933685\n",
       "230785  20O0017860  0.153807  0.846193\n",
       "\n",
       "[230786 rows x 3 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3 = df2.reset_index(level=None)\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 230786 entries, 0 to 230785\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count   Dtype  \n",
      "---  ------     --------------   -----  \n",
      " 0   index      230786 non-null  int64  \n",
      " 1   Serial ID  230786 non-null  object \n",
      " 2   False      230786 non-null  float64\n",
      " 3   True       230786 non-null  float64\n",
      "dtypes: float64(2), int64(1), object(1)\n",
      "memory usage: 7.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df3.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Serial ID</th>\n",
       "      <th>Churn</th>\n",
       "      <th>Sales Organisation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>MYBMB25820</td>\n",
       "      <td>False</td>\n",
       "      <td>Malaysia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>22O0025413</td>\n",
       "      <td>False</td>\n",
       "      <td>Nestlé India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>22O0023817</td>\n",
       "      <td>False</td>\n",
       "      <td>Nestlé India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>22O0023735</td>\n",
       "      <td>False</td>\n",
       "      <td>Nestlé India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>22O0023729</td>\n",
       "      <td>False</td>\n",
       "      <td>Nestlé India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230781</th>\n",
       "      <td>230781</td>\n",
       "      <td>20O0017858</td>\n",
       "      <td>True</td>\n",
       "      <td>Singapore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230782</th>\n",
       "      <td>230782</td>\n",
       "      <td>20O0017859</td>\n",
       "      <td>True</td>\n",
       "      <td>Singapore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230783</th>\n",
       "      <td>230783</td>\n",
       "      <td>20O0017862</td>\n",
       "      <td>True</td>\n",
       "      <td>Singapore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230784</th>\n",
       "      <td>230784</td>\n",
       "      <td>20O0017861</td>\n",
       "      <td>True</td>\n",
       "      <td>Singapore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230785</th>\n",
       "      <td>230785</td>\n",
       "      <td>20O0017860</td>\n",
       "      <td>True</td>\n",
       "      <td>Singapore</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>230786 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         index   Serial ID  Churn Sales Organisation\n",
       "0            0  MYBMB25820  False           Malaysia\n",
       "1            1  22O0025413  False       Nestlé India\n",
       "2            2  22O0023817  False       Nestlé India\n",
       "3            3  22O0023735  False       Nestlé India\n",
       "4            4  22O0023729  False       Nestlé India\n",
       "...        ...         ...    ...                ...\n",
       "230781  230781  20O0017858   True          Singapore\n",
       "230782  230782  20O0017859   True          Singapore\n",
       "230783  230783  20O0017862   True          Singapore\n",
       "230784  230784  20O0017861   True          Singapore\n",
       "230785  230785  20O0017860   True          Singapore\n",
       "\n",
       "[230786 rows x 4 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df21 = pd.DataFrame(BeverageMachine_withSerial[['Serial ID','Churn', 'Sales Organisation']]).reset_index(level=None)\n",
    "df21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 230786 entries, 0 to 230785\n",
      "Data columns (total 4 columns):\n",
      " #   Column              Non-Null Count   Dtype \n",
      "---  ------              --------------   ----- \n",
      " 0   index               230786 non-null  int64 \n",
      " 1   Serial ID           230786 non-null  object\n",
      " 2   Churn               230786 non-null  bool  \n",
      " 3   Sales Organisation  230786 non-null  object\n",
      "dtypes: bool(1), int64(1), object(2)\n",
      "memory usage: 5.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df21.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3['Serial ID'] = df3['Serial ID'].astype('str')\n",
    "df21['Serial ID'] = df21['Serial ID'].astype('str')\n",
    "df3['index'] = df3['index'].astype('str')\n",
    "df21['index'] = df21['index'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3['KeyIndSer'] = df3['index'] + \"-\" + df3['Serial ID']\n",
    "df21['KeyIndSer'] = df21['index'] + \"-\" + df21['Serial ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = pd.merge(df3, df21, how='left', left_on = ['KeyIndSer'], right_on = ['KeyIndSer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index_x</th>\n",
       "      <th>Serial ID_x</th>\n",
       "      <th>False</th>\n",
       "      <th>True</th>\n",
       "      <th>KeyIndSer</th>\n",
       "      <th>index_y</th>\n",
       "      <th>Serial ID_y</th>\n",
       "      <th>Churn</th>\n",
       "      <th>Sales Organisation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>MYBMB25820</td>\n",
       "      <td>0.858197</td>\n",
       "      <td>0.141803</td>\n",
       "      <td>0-MYBMB25820</td>\n",
       "      <td>0</td>\n",
       "      <td>MYBMB25820</td>\n",
       "      <td>False</td>\n",
       "      <td>Malaysia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>22O0025413</td>\n",
       "      <td>0.955200</td>\n",
       "      <td>0.044800</td>\n",
       "      <td>1-22O0025413</td>\n",
       "      <td>1</td>\n",
       "      <td>22O0025413</td>\n",
       "      <td>False</td>\n",
       "      <td>Nestlé India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>22O0023817</td>\n",
       "      <td>0.601167</td>\n",
       "      <td>0.398833</td>\n",
       "      <td>2-22O0023817</td>\n",
       "      <td>2</td>\n",
       "      <td>22O0023817</td>\n",
       "      <td>False</td>\n",
       "      <td>Nestlé India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>22O0023735</td>\n",
       "      <td>0.695519</td>\n",
       "      <td>0.304481</td>\n",
       "      <td>3-22O0023735</td>\n",
       "      <td>3</td>\n",
       "      <td>22O0023735</td>\n",
       "      <td>False</td>\n",
       "      <td>Nestlé India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>22O0023729</td>\n",
       "      <td>0.640347</td>\n",
       "      <td>0.359653</td>\n",
       "      <td>4-22O0023729</td>\n",
       "      <td>4</td>\n",
       "      <td>22O0023729</td>\n",
       "      <td>False</td>\n",
       "      <td>Nestlé India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230781</th>\n",
       "      <td>230781</td>\n",
       "      <td>20O0017858</td>\n",
       "      <td>0.021987</td>\n",
       "      <td>0.978013</td>\n",
       "      <td>230781-20O0017858</td>\n",
       "      <td>230781</td>\n",
       "      <td>20O0017858</td>\n",
       "      <td>True</td>\n",
       "      <td>Singapore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230782</th>\n",
       "      <td>230782</td>\n",
       "      <td>20O0017859</td>\n",
       "      <td>0.006570</td>\n",
       "      <td>0.993430</td>\n",
       "      <td>230782-20O0017859</td>\n",
       "      <td>230782</td>\n",
       "      <td>20O0017859</td>\n",
       "      <td>True</td>\n",
       "      <td>Singapore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230783</th>\n",
       "      <td>230783</td>\n",
       "      <td>20O0017862</td>\n",
       "      <td>0.091315</td>\n",
       "      <td>0.908685</td>\n",
       "      <td>230783-20O0017862</td>\n",
       "      <td>230783</td>\n",
       "      <td>20O0017862</td>\n",
       "      <td>True</td>\n",
       "      <td>Singapore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230784</th>\n",
       "      <td>230784</td>\n",
       "      <td>20O0017861</td>\n",
       "      <td>0.066315</td>\n",
       "      <td>0.933685</td>\n",
       "      <td>230784-20O0017861</td>\n",
       "      <td>230784</td>\n",
       "      <td>20O0017861</td>\n",
       "      <td>True</td>\n",
       "      <td>Singapore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230785</th>\n",
       "      <td>230785</td>\n",
       "      <td>20O0017860</td>\n",
       "      <td>0.153807</td>\n",
       "      <td>0.846193</td>\n",
       "      <td>230785-20O0017860</td>\n",
       "      <td>230785</td>\n",
       "      <td>20O0017860</td>\n",
       "      <td>True</td>\n",
       "      <td>Singapore</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>230786 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index_x Serial ID_x     False      True          KeyIndSer index_y  \\\n",
       "0            0  MYBMB25820  0.858197  0.141803       0-MYBMB25820       0   \n",
       "1            1  22O0025413  0.955200  0.044800       1-22O0025413       1   \n",
       "2            2  22O0023817  0.601167  0.398833       2-22O0023817       2   \n",
       "3            3  22O0023735  0.695519  0.304481       3-22O0023735       3   \n",
       "4            4  22O0023729  0.640347  0.359653       4-22O0023729       4   \n",
       "...        ...         ...       ...       ...                ...     ...   \n",
       "230781  230781  20O0017858  0.021987  0.978013  230781-20O0017858  230781   \n",
       "230782  230782  20O0017859  0.006570  0.993430  230782-20O0017859  230782   \n",
       "230783  230783  20O0017862  0.091315  0.908685  230783-20O0017862  230783   \n",
       "230784  230784  20O0017861  0.066315  0.933685  230784-20O0017861  230784   \n",
       "230785  230785  20O0017860  0.153807  0.846193  230785-20O0017860  230785   \n",
       "\n",
       "       Serial ID_y  Churn Sales Organisation  \n",
       "0       MYBMB25820  False           Malaysia  \n",
       "1       22O0025413  False       Nestlé India  \n",
       "2       22O0023817  False       Nestlé India  \n",
       "3       22O0023735  False       Nestlé India  \n",
       "4       22O0023729  False       Nestlé India  \n",
       "...            ...    ...                ...  \n",
       "230781  20O0017858   True          Singapore  \n",
       "230782  20O0017859   True          Singapore  \n",
       "230783  20O0017862   True          Singapore  \n",
       "230784  20O0017861   True          Singapore  \n",
       "230785  20O0017860   True          Singapore  \n",
       "\n",
       "[230786 rows x 9 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.to_csv(r'C:\\Users\\msalomo\\predictions-Churn-RandomForest2.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'#months of data', 'Depreciation Start',\n",
    "       'Industry (EC ID)_0614 InStore Food Service',\n",
    "       'End Date in Local Time Zone_x', \n",
    "       'G/R/M TB_MTB (Market)', 'Position_#', 'Position_LOAN',\n",
    "       'Incident Category_New Customer / Installation Point',\n",
    "       'User Status_Installed', 'Model Group_Other',\n",
    "       'User Status_To be removed', 'Service Category_Installation.',\n",
    "       'Last_visit_diff_months', 'Model Vendor_SAI Vending',\n",
    "       'Trading Partner_Direct', 'End Date in Local Time Zone_y',\n",
    "       'Industry (EC ID)_0614 Convenience OOH',\n",
    "       'System Brands_Nescafé Branded'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest generally outperforms Decision Tree for accuracy, which is the case. \n",
    "I am focusing on the F1_macro score, and here Random Forest also outperforms decision tree for F1_macro."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
