{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone proposal by Mirko Salomon \n",
    "\n",
    "# BEVERAGE MACHINE CHURN PREDICTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ## [1) Introduction and preparation](#Introduction) \n",
    "\n",
    "    *   \n",
    "        #### Data Load\n",
    "        \n",
    "        #### Hyperparameters\n",
    "        \n",
    "* ## [2) Random Forest model](#RF)\n",
    "    \n",
    "    *   \n",
    "        #### Train the model\n",
    "        \n",
    "        #### Test data with best parameters \n",
    "        \n",
    "        #### Confusion Matrix\n",
    "        \n",
    "        #### Tree Plot\n",
    "        \n",
    "        #### Prediction of churn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Introduction and preparation<a class=\"anchor\" id=\"Introduction\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forests are an ensemble learning method for classification that operate by constructing a multitude of decision trees at training time and outputting the class that is the mode of the classes (classification) or mean/average prediction (regression) of the individual trees.\n",
    "\n",
    "Based on the flowchart from Scikit Learn I should try a Random Forest model.\n",
    "\n",
    "This model is a bit more a black box than a regression or decision tree\n",
    "\n",
    "Has predict_proba that predicts class probabilities for X, can handle well categorical features, maintains accuracy when the data is missing\n",
    "\n",
    "Seems to have good Performance on Imbalanced datasets and we can also modify the weights\n",
    "\n",
    "Is a model working differently than a regression model and performs usually better than a decision tree\n",
    "\n",
    "I will tune the number of estimators and the maximum number of features. I will also tune the class weigth and the bootstrap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "import xlrd\n",
    "\n",
    "import datetime as dt\n",
    "from datetime import datetime\n",
    "\n",
    "import collections\n",
    "from collections import Counter\n",
    "\n",
    "# Import seaborn\n",
    "import seaborn as sns\n",
    "\n",
    "# Specify the file path\n",
    "file_path = r'C:\\Users\\msalomo\\OneDrive - NESTLE\\Certificate Machine Learning and Data\\Churn Project\\Notebook output'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conda update -c conda-forge scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install --upgrade scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#libraries\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Import Random Forest Model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "from sklearn import metrics \n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#from sklearn.metrics import plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the filename\n",
    "filename = 'BM_noTickets_preprocess.p'\n",
    "\n",
    "# Combine the file path and filename\n",
    "file_path_with_filename = os.path.join(file_path, filename)\n",
    "\n",
    "# Load the pickle file\n",
    "with open(file_path_with_filename, 'rb') as file:\n",
    "    BM_noTickets_preprocess = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pickle file 'X.p'\n",
    "with open(os.path.join(file_path, 'X.p'), 'rb') as file:\n",
    "    X = pickle.load(file)\n",
    "\n",
    "# Load the pickle file 'y.p'\n",
    "with open(os.path.join(file_path, 'y.p'), 'rb') as file:\n",
    "    y = pickle.load(file)\n",
    "\n",
    "# Load the pickle file 'X_tr.p'\n",
    "with open(os.path.join(file_path, 'X_tr.p'), 'rb') as file:\n",
    "    X_tr = pickle.load(file)\n",
    "\n",
    "# Load the pickle file 'y_tr.p'\n",
    "with open(os.path.join(file_path, 'y_tr.p'), 'rb') as file:\n",
    "    y_tr = pickle.load(file)\n",
    "\n",
    "# Load the pickle file 'X_val.p'\n",
    "with open(os.path.join(file_path, 'X_val.p'), 'rb') as file:\n",
    "    X_val = pickle.load(file)\n",
    "\n",
    "# Load the pickle file 'y_val.p'\n",
    "with open(os.path.join(file_path, 'y_val.p'), 'rb') as file:\n",
    "    y_val = pickle.load(file)\n",
    "\n",
    "# Load the pickle file 'X_te.p'\n",
    "with open(os.path.join(file_path, 'X_te.p'), 'rb') as file:\n",
    "    X_te = pickle.load(file)\n",
    "\n",
    "# Load the pickle file 'y_te.p'\n",
    "with open(os.path.join(file_path, 'y_te.p'), 'rb') as file:\n",
    "    y_te = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TA Contract Installation Date</th>\n",
       "      <th>Depreciation Start</th>\n",
       "      <th>TA Contract Start Date</th>\n",
       "      <th>TA Contract End Date</th>\n",
       "      <th>Churn</th>\n",
       "      <th>Service Category_Installation</th>\n",
       "      <th>Service Category_Removal</th>\n",
       "      <th>Service Category_Replacement</th>\n",
       "      <th>INCIDENT_CATEGORY_DESCRIPTION_Customer relocation</th>\n",
       "      <th>INCIDENT_CATEGORY_DESCRIPTION_Exchange / Replacement Sales</th>\n",
       "      <th>...</th>\n",
       "      <th>Generation_Gen. 2</th>\n",
       "      <th>Generation_Legacy</th>\n",
       "      <th>Blueprint Throughput_%23-N/A</th>\n",
       "      <th>Blueprint Throughput_High</th>\n",
       "      <th>Blueprint Throughput_Low</th>\n",
       "      <th>Blueprint Throughput_Medium</th>\n",
       "      <th>IP Ownership_Exclusive</th>\n",
       "      <th>IP Ownership_Non-Proprietary</th>\n",
       "      <th>IP Ownership_Propr. Comp.</th>\n",
       "      <th>IP Ownership_Proprietary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1924.0</td>\n",
       "      <td>5325.0</td>\n",
       "      <td>1897.0</td>\n",
       "      <td>355.683599</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1924.0</td>\n",
       "      <td>2131.0</td>\n",
       "      <td>1897.0</td>\n",
       "      <td>355.683599</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1924.0</td>\n",
       "      <td>2314.0</td>\n",
       "      <td>1897.0</td>\n",
       "      <td>355.683599</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1924.0</td>\n",
       "      <td>2131.0</td>\n",
       "      <td>1897.0</td>\n",
       "      <td>355.683599</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1924.0</td>\n",
       "      <td>6161.0</td>\n",
       "      <td>1897.0</td>\n",
       "      <td>355.683599</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1385 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   TA Contract Installation Date  Depreciation Start  TA Contract Start Date  \\\n",
       "0                         1924.0              5325.0                  1897.0   \n",
       "1                         1924.0              2131.0                  1897.0   \n",
       "2                         1924.0              2314.0                  1897.0   \n",
       "3                         1924.0              2131.0                  1897.0   \n",
       "4                         1924.0              6161.0                  1897.0   \n",
       "\n",
       "   TA Contract End Date  Churn  Service Category_Installation  \\\n",
       "0            355.683599  False                            0.0   \n",
       "1            355.683599  False                            0.0   \n",
       "2            355.683599  False                            0.0   \n",
       "3            355.683599  False                            0.0   \n",
       "4            355.683599  False                            0.0   \n",
       "\n",
       "   Service Category_Removal  Service Category_Replacement  \\\n",
       "0                       0.0                           0.0   \n",
       "1                       0.0                           0.0   \n",
       "2                       0.0                           1.0   \n",
       "3                       0.0                           1.0   \n",
       "4                       0.0                           0.0   \n",
       "\n",
       "   INCIDENT_CATEGORY_DESCRIPTION_Customer relocation  \\\n",
       "0                                                0.0   \n",
       "1                                                0.0   \n",
       "2                                                0.0   \n",
       "3                                                0.0   \n",
       "4                                                0.0   \n",
       "\n",
       "   INCIDENT_CATEGORY_DESCRIPTION_Exchange / Replacement Sales  ...  \\\n",
       "0                                                0.0           ...   \n",
       "1                                                0.0           ...   \n",
       "2                                                0.0           ...   \n",
       "3                                                0.0           ...   \n",
       "4                                                0.0           ...   \n",
       "\n",
       "   Generation_Gen. 2  Generation_Legacy  Blueprint Throughput_%23-N/A  \\\n",
       "0                  0                  0                             0   \n",
       "1                  0                  0                             0   \n",
       "2                  0                  0                             0   \n",
       "3                  0                  0                             0   \n",
       "4                  0                  1                             0   \n",
       "\n",
       "   Blueprint Throughput_High  Blueprint Throughput_Low  \\\n",
       "0                          0                         0   \n",
       "1                          0                         0   \n",
       "2                          0                         0   \n",
       "3                          0                         0   \n",
       "4                          0                         0   \n",
       "\n",
       "   Blueprint Throughput_Medium  IP Ownership_Exclusive  \\\n",
       "0                            1                       0   \n",
       "1                            1                       0   \n",
       "2                            1                       0   \n",
       "3                            1                       0   \n",
       "4                            1                       0   \n",
       "\n",
       "   IP Ownership_Non-Proprietary  IP Ownership_Propr. Comp.  \\\n",
       "0                             0                          0   \n",
       "1                             0                          1   \n",
       "2                             0                          1   \n",
       "3                             0                          1   \n",
       "4                             1                          0   \n",
       "\n",
       "   IP Ownership_Proprietary  \n",
       "0                         1  \n",
       "1                         0  \n",
       "2                         0  \n",
       "3                         0  \n",
       "4                         0  \n",
       "\n",
       "[5 rows x 1385 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BM_noTickets_preprocess.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 252265 entries, 0 to 252264\n",
      "Columns: 1385 entries, TA Contract Installation Date to IP Ownership_Proprietary\n",
      "dtypes: bool(1), float64(103), int32(2), int64(2), object(1), uint8(1276)\n",
      "memory usage: 515.1+ MB\n"
     ]
    }
   ],
   "source": [
    "BM_noTickets_preprocess.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class sklearn.ensemble.RandomForestClassifier(n_estimators=100, *, criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='auto', max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, bootstrap=True, oob_score=False, n_jobs=None, random_state=None, verbose=0, warm_start=False, class_weight=None, ccp_alpha=0.0, max_samples=None)\n",
    "\n",
    "---\n",
    "\n",
    "The number of trees in the forest. I will try some.\n",
    "\n",
    "n_estimators = range(20,200,20)\n",
    "\n",
    "---\n",
    "\n",
    "The maximum depth of the tree. I will try some.\n",
    "\n",
    "max_depth = (20, 50, 100, None)\n",
    "\n",
    "---\n",
    "\n",
    "The function to measure the quality of a split. I will try both.\n",
    "\n",
    "criterion = ('gini', 'entropy')\n",
    "\n",
    "---\n",
    "\n",
    "Whether bootstrap samples are used when building trees. If False, the whole dataset is used to build each tree.\n",
    "I will try both.\n",
    "\n",
    "bootstrap = (True, False)\n",
    "\n",
    "---\n",
    "\n",
    "Weights associated with classes in the form.\n",
    "\n",
    "class_weight = ('balanced', None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Random Forest model<a class=\"anchor\" id=\"RF\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(141268,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(141268, 1384)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50453, 1384)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(X_te)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# Define a set of reasonable values\n",
    "#n_estimators = range(20,160,20) # I tried till 200 but it was not in the top results, so I reduced to 160\n",
    "n_estimators = range(20,120,60) # I tried till 200 but it was not in the top results, so I reduced to 160\n",
    "\n",
    "#max_depth = (20, 50, 10, None) # I tried with 200, 300, but results were not better\n",
    "max_depth = (20, 50, None) # I tried with 200, 300, but results were not better\n",
    "\n",
    "criterion = ('gini', 'entropy')\n",
    "#bootstrap = (True, False)\n",
    "bootstrap = (True)\n",
    "class_weight = ('balanced', None) # I tried with  'balanced_subsample', but I had lower scores.\n",
    "\n",
    "\n",
    "# Define a parameter grid of values\n",
    "grid = ParameterGrid({'rf__n_estimators' : n_estimators,\n",
    "                    'rf__max_depth' : max_depth,\n",
    "                    'rf__criterion' :  criterion,\n",
    "                    'rf__bootstrap' : (True, False),\n",
    "                    'rf__class_weight' : class_weight \n",
    "                   }\n",
    "                  )\n",
    " \n",
    "\n",
    "# Create pipeline, random forest classifier\n",
    "pipe = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('rf', RandomForestClassifier(random_state=1))\n",
    "    ]\n",
    ")\n",
    "   \n",
    "# Save accuracy on test set\n",
    "test_scores = []\n",
    "\n",
    "for params_dict in grid:\n",
    "    # Set parameters\n",
    "    pipe.set_params(**params_dict)\n",
    "\n",
    "    # Fit a k-NN classifier\n",
    "    pipe.fit(X_tr, y_tr)\n",
    "\n",
    "    # Save accuracy on validation set\n",
    "    params_dict['accuracy'] = pipe.score(X_val, y_val)\n",
    "    # Save f1 score on validation set\n",
    "    # predict test instances\n",
    "    y_pred = pipe.predict(X_val)\n",
    "    params_dict['f1_macro'] = metrics.f1_score(y_val, y_pred, average='macro')\n",
    "    \n",
    "    # Save result\n",
    "    test_scores.append(params_dict)\n",
    "    \n",
    "# Create DataFrame with test scores\n",
    "scores_df = pd.DataFrame(test_scores)\n",
    "\n",
    "# Top five scores\n",
    "scores_df.sort_values(by='f1_macro', ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "rf = RandomForestClassifier(random_state=1)\n",
    "rf.fit(X_tr, y_tr)\n",
    "y_pred = rf.predict(X_te) # Predictions\n",
    "y_true = y_te # True values\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Train accuracy:\", np.round(accuracy_score(y_tr, \n",
    "                                                 rfc.predict(X_tr)), 2))\n",
    "print(\"Test accuracy:\", np.round(accuracy_score(y_true, y_pred), 2))\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cf_matrix = confusion_matrix(y_true, y_pred)\n",
    "print(\"\\nTest confusion_matrix\")\n",
    "sns.heatmap(cf_matrix, annot=True, cmap='Blues')\n",
    "plt.xlabel('Predicted', fontsize=12)\n",
    "plt.ylabel('True', fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "estimator.get_params().keys()\n",
    "param = {'rf__n_estimators' : n_estimators,\n",
    "         'rf__max_depth' : max_depth,\n",
    "         'rf__criterion' :  criterion,\n",
    "         'rf__bootstrap' : (True, False),\n",
    "         'rf__class_weight' : class_weight \n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's measure execution time too\n",
    "import time\n",
    "start = time.time()\n",
    "\n",
    "# Define a set of reasonable values\n",
    "n_estimators = range(20,160,20) # I tried till 200 but it was not in the top results, so I reduced to 160\n",
    "max_depth = (20, 50, 10, None) # I tried with 200, 300, but results were not better\n",
    "criterion = ('gini', 'entropy')\n",
    "bootstrap = (True, False)\n",
    "class_weight = ('balanced', None) # I tried with  'balanced_subsample', but I had lower scores.\n",
    "\n",
    "\n",
    "# Defining 3-dimensional hyperparameter space as a Python dictionary\n",
    "#hyperparameter_space = {'rf__n_estimators' : n_estimators, 'rf__max_depth' : max_depth,\n",
    "#                    'rf__criterion' :  criterion,\n",
    "#                    'rf__bootstrap' : (True, False),\n",
    "#                    'rf__class_weight' : class_weight \n",
    "\n",
    "#param = {'rf__n_estimators' : n_estimators,\n",
    "#         'rf__max_depth' : max_depth,\n",
    "#         'rf__max_depth' : max_depth,\n",
    "#         'rf__criterion' :  criterion,\n",
    "#         'rf__bootstrap' : (True, False),\n",
    "#         'rf__class_weight' : class_weight \n",
    "#        }\n",
    "\n",
    "random_grid = {'bootstrap': [True, False],\n",
    "               'max_depth': [10, None],\n",
    "               'min_samples_leaf': [1, 4],\n",
    "               'min_samples_split': [2, 5],\n",
    "               'n_estimators': [130, 230]}\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "#rs = RandomizedSearchCV(rfc, param_distributions=hyperparameter_space,\n",
    "#                        n_iter=10, scoring= 'f1_macro', random_state=1,\n",
    "#                        n_jobs=-1, cv=10, return_train_score=True)\n",
    "\n",
    "\n",
    "#rs = RandomizedSearchCV(rf, param, n_iter =10, cv=9)\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, verbose=2, random_state=42, n_jobs = -1)\n",
    "\n",
    "rf_random.fit(X_tr, y_tr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#rs.fit(X_tr, y_tr)\n",
    "print(\"Optimal hyperparameter combination:\", rs.best_params_)\n",
    "print()\n",
    "print(\"Mean cross-validated training accuracy score:\",\n",
    "      rs.best_score_)\n",
    "rs.best_estimator_.fit(X_tr, y_tr)\n",
    "y_pred = rs.best_estimator_.predict(X_te) # Predictions\n",
    "y_true = y_te # True values\n",
    "\n",
    "print(\"Test accuracy:\", np.round(accuracy_score(y_true, y_pred), 2))\n",
    "cf_matrix = confusion_matrix(y_true, y_pred)\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.heatmap(cf_matrix, annot=True, cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "\n",
    "end = time.time()\n",
    "diff = end - start\n",
    "print('Execution time of Random Search (in Seconds):', diff)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cv_results = rf_random.cv_results_\n",
    "for mean_score, params in zip(cv_results[\"mean_test_score\"], cvres[\"params\"]):\n",
    "    print(np.sqrt(-mean_score), params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rf__n_estimators</th>\n",
       "      <th>rf__max_depth</th>\n",
       "      <th>rf__criterion</th>\n",
       "      <th>rf__bootstrap</th>\n",
       "      <th>rf__class_weight</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>80</td>\n",
       "      <td>50</td>\n",
       "      <td>entropy</td>\n",
       "      <td>False</td>\n",
       "      <td>balanced</td>\n",
       "      <td>0.872277</td>\n",
       "      <td>0.861224</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rf__n_estimators  rf__max_depth rf__criterion  rf__bootstrap  \\\n",
       "0                80             50       entropy          False   \n",
       "\n",
       "  rf__class_weight  accuracy  f1_macro  \n",
       "0         balanced  0.872277  0.861224  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_dict = {'rf__n_estimators': 80, \n",
    " 'rf__max_depth': 50, \n",
    " 'rf__criterion': 'entropy', \n",
    " 'rf__bootstrap': False, \n",
    " 'rf__class_weight': 'balanced'}\n",
    "\n",
    "# Create pipeline, random forest classifier\n",
    "pipe = Pipeline([\n",
    "    #('oversample', SmoteSample_model),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('rf', RandomForestClassifier(random_state=1))\n",
    "    ]\n",
    ")\n",
    "  \n",
    "# Save accuracy on test set\n",
    "test_scores = []\n",
    "\n",
    "# Set parameters\n",
    "pipe.set_params(**params_dict)\n",
    "\n",
    "# Fit a k-NN classifier\n",
    "pipe.fit(X_tr, y_tr)\n",
    "\n",
    "# Save accuracy on validation set\n",
    "params_dict['accuracy'] = pipe.score(X_te, y_te)\n",
    "# Save f1 score on validation set\n",
    "# predict test instances\n",
    "y_pred = pipe.predict(X_te)\n",
    "params_dict['f1_macro'] = metrics.f1_score(y_te, y_pred, average='macro')\n",
    "    \n",
    "# Save result\n",
    "test_scores.append(params_dict)\n",
    "    \n",
    "# Create DataFrame with test scores\n",
    "scores_df = pd.DataFrame(test_scores)\n",
    "\n",
    "# Top five scores\n",
    "scores_df.sort_values(by='f1_macro', ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have an F1 Macro score of 83.8% and an accuracy of 93.7% with the test data. Which is close to the validation data results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# F1_score\n",
    "RF_F1Macro = params_dict['f1_macro']\n",
    "\n",
    "# Accuracy\n",
    "RF_accuracy = params_dict['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_Results: [0.57434612 0.         0.         0.         0.86122365 0.\n",
      " 0.         0.        ]\n",
      "Accuracy: [0.70661804 0.         0.         0.         0.87227717 0.\n",
      " 0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "# Specify the filename\n",
    "filename = 'Results.npz'\n",
    "\n",
    "# Combine the file path and filename\n",
    "file_path_with_filename = os.path.join(file_path, filename)\n",
    "\n",
    "# Load the npz file for results\n",
    "with np.load(file_path_with_filename, allow_pickle=False) as npz_file:\n",
    "    F1Score = npz_file['test_F1Score']\n",
    "    accuracy = npz_file['test_accuracy']\n",
    "    models = npz_file['models']\n",
    "    \n",
    "# Fill the calculated result value\n",
    "F1Score[4] = RF_F1Macro\n",
    "accuracy[4] = RF_accuracy\n",
    "\n",
    "print('F1_Results:', F1Score)\n",
    "print('Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify the Numpy array\n",
    "#Model = models #unchanged\n",
    "Result = F1Score\n",
    "Accuracy = accuracy\n",
    "\n",
    "# Specify the filename\n",
    "filename = 'Results.npz'\n",
    "\n",
    "# Combine the file path and filename\n",
    "file_path_with_filename = os.path.join(file_path, filename)\n",
    "\n",
    "# Store the changes in the results npz file\n",
    "np.savez(file_path_with_filename, models=models, test_F1Score=Result, test_accuracy=Accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['models', 'test_F1Score', 'test_accuracy']\n",
      "Models: ['Baseline' 'Logistic Regression' 'KNeighbors' 'Decision Tree'\n",
      " 'Random Forest' 'XGBoost' 'SelectedModel_wTickets'\n",
      " 'SelectedModel_wTickets&Telemetry']\n",
      "F1_Results: [0.57434612 0.         0.         0.         0.86122365 0.\n",
      " 0.         0.        ]\n",
      "Accuracy: [0.70661804 0.         0.         0.         0.87227717 0.\n",
      " 0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "# Check the refreshed results\n",
    "# Specify the filename\n",
    "filename = 'Results.npz'\n",
    "\n",
    "# Combine the file path and filename\n",
    "file_path_with_filename = os.path.join(file_path, filename)\n",
    "\n",
    "# Load the npz file for results\n",
    "with np.load(file_path_with_filename, allow_pickle=False) as npz_file:\n",
    "    # It's a dictionary-like object\n",
    "    print(list(npz_file.keys()))\n",
    "    # Load the arrays\n",
    "    print('Models:', npz_file['models'])\n",
    "    print('F1_Results:', npz_file['test_F1Score'])\n",
    "    print('Accuracy:', npz_file['test_accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[29124  2764]\n",
      " [ 3680 14885]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False      0.888     0.913     0.900     31888\n",
      "        True      0.843     0.802     0.822     18565\n",
      "\n",
      "    accuracy                          0.872     50453\n",
      "   macro avg      0.866     0.858     0.861     50453\n",
      "weighted avg      0.871     0.872     0.872     50453\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Classification reports and confusion matrices are commonly used for reporting the performance of classifiers when working with imbalanced datasets.\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(metrics.confusion_matrix(y_te, y_pred))\n",
    "\n",
    "# Print the precision and recall, among other metrics\n",
    "print(metrics.classification_report(y_te, y_pred, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>False Condition</th>\n",
       "      <th>True Condition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Predicted False</th>\n",
       "      <td>29124</td>\n",
       "      <td>3680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predicted True</th>\n",
       "      <td>2764</td>\n",
       "      <td>14885</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 False Condition  True Condition\n",
       "Predicted False            29124            3680\n",
       "Predicted True              2764           14885"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Classification reports and confusion matrices are commonly used for reporting the performance of classifiers when working with imbalanced datasets.\n",
    "ConfMat_df = pd.DataFrame(metrics.confusion_matrix(y_te, y_pred).T, columns=['False Condition', 'True Condition'],index=['Predicted False', 'Predicted True'])\n",
    "ConfMat_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a good F1 Score for the False Condition but not as good for the True Condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the filename\n",
    "filename = 'Random Forest_ConfMat_df.p'\n",
    "\n",
    "# Combine the file path and filename\n",
    "file_path_with_filename = os.path.join(file_path, filename)\n",
    "\n",
    "# Save the DataFrame into a pickle file\n",
    "with open(file_path_with_filename, 'wb') as file:\n",
    "    pickle.dump(ConfMat_df, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction of churn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Churn prediction from the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the filename\n",
    "filename = 'BeverageMachine_withSerial.p'\n",
    "\n",
    "# Combine the file path and filename\n",
    "file_path_with_filename = os.path.join(file_path, filename)\n",
    "\n",
    "# Load the pickle file\n",
    "with open(file_path_with_filename, 'rb') as file:\n",
    "    BeverageMachine_withSerial = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "name = ['False', 'True']\n",
    "No=BeverageMachine_withSerial['Serial ID']\n",
    "predictions = pipe.predict_proba(X)\n",
    "# With two column indices, values same  \n",
    "# as dictionary keys \n",
    "df2 = pd.DataFrame(predictions, index=No ,columns = name) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial ID</th>\n",
       "      <th>False</th>\n",
       "      <th>True</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TH10127992</td>\n",
       "      <td>0.999143</td>\n",
       "      <td>0.000857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TH10213045</td>\n",
       "      <td>0.461446</td>\n",
       "      <td>0.538554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TH10212610</td>\n",
       "      <td>0.872295</td>\n",
       "      <td>0.127705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TH10213000</td>\n",
       "      <td>0.857011</td>\n",
       "      <td>0.142989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TH10108148</td>\n",
       "      <td>0.897466</td>\n",
       "      <td>0.102534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252260</th>\n",
       "      <td>20O0017852</td>\n",
       "      <td>0.074047</td>\n",
       "      <td>0.925953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252261</th>\n",
       "      <td>20O0017851</td>\n",
       "      <td>0.097694</td>\n",
       "      <td>0.902306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252262</th>\n",
       "      <td>20O0017860</td>\n",
       "      <td>0.009865</td>\n",
       "      <td>0.990135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252263</th>\n",
       "      <td>20O0017861</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252264</th>\n",
       "      <td>20O0017862</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>252265 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Serial ID     False      True\n",
       "0       TH10127992  0.999143  0.000857\n",
       "1       TH10213045  0.461446  0.538554\n",
       "2       TH10212610  0.872295  0.127705\n",
       "3       TH10213000  0.857011  0.142989\n",
       "4       TH10108148  0.897466  0.102534\n",
       "...            ...       ...       ...\n",
       "252260  20O0017852  0.074047  0.925953\n",
       "252261  20O0017851  0.097694  0.902306\n",
       "252262  20O0017860  0.009865  0.990135\n",
       "252263  20O0017861  0.000000  1.000000\n",
       "252264  20O0017862  0.000000  1.000000\n",
       "\n",
       "[252265 rows x 3 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3 = df2.reset_index(level=None)\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 252265 entries, 0 to 252264\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count   Dtype  \n",
      "---  ------     --------------   -----  \n",
      " 0   index      252265 non-null  int64  \n",
      " 1   Serial ID  252265 non-null  object \n",
      " 2   False      252265 non-null  float64\n",
      " 3   True       252265 non-null  float64\n",
      "dtypes: float64(2), int64(1), object(1)\n",
      "memory usage: 7.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df3.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Serial ID</th>\n",
       "      <th>Churn</th>\n",
       "      <th>Sales Organisation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>TH10127992</td>\n",
       "      <td>False</td>\n",
       "      <td>Thailand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>TH10213045</td>\n",
       "      <td>False</td>\n",
       "      <td>Thailand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>TH10212610</td>\n",
       "      <td>False</td>\n",
       "      <td>Thailand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>TH10213000</td>\n",
       "      <td>False</td>\n",
       "      <td>Thailand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>TH10108148</td>\n",
       "      <td>False</td>\n",
       "      <td>Thailand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252260</th>\n",
       "      <td>252260</td>\n",
       "      <td>20O0017852</td>\n",
       "      <td>True</td>\n",
       "      <td>Singapore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252261</th>\n",
       "      <td>252261</td>\n",
       "      <td>20O0017851</td>\n",
       "      <td>True</td>\n",
       "      <td>Singapore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252262</th>\n",
       "      <td>252262</td>\n",
       "      <td>20O0017860</td>\n",
       "      <td>True</td>\n",
       "      <td>Singapore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252263</th>\n",
       "      <td>252263</td>\n",
       "      <td>20O0017861</td>\n",
       "      <td>True</td>\n",
       "      <td>Singapore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252264</th>\n",
       "      <td>252264</td>\n",
       "      <td>20O0017862</td>\n",
       "      <td>True</td>\n",
       "      <td>Singapore</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>252265 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         index   Serial ID  Churn Sales Organisation\n",
       "0            0  TH10127992  False           Thailand\n",
       "1            1  TH10213045  False           Thailand\n",
       "2            2  TH10212610  False           Thailand\n",
       "3            3  TH10213000  False           Thailand\n",
       "4            4  TH10108148  False           Thailand\n",
       "...        ...         ...    ...                ...\n",
       "252260  252260  20O0017852   True          Singapore\n",
       "252261  252261  20O0017851   True          Singapore\n",
       "252262  252262  20O0017860   True          Singapore\n",
       "252263  252263  20O0017861   True          Singapore\n",
       "252264  252264  20O0017862   True          Singapore\n",
       "\n",
       "[252265 rows x 4 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df21 = pd.DataFrame(BeverageMachine_withSerial[['Serial ID','Churn', 'Sales Organisation']]).reset_index(level=None)\n",
    "df21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 252265 entries, 0 to 252264\n",
      "Data columns (total 4 columns):\n",
      " #   Column              Non-Null Count   Dtype \n",
      "---  ------              --------------   ----- \n",
      " 0   index               252265 non-null  int64 \n",
      " 1   Serial ID           252265 non-null  object\n",
      " 2   Churn               252265 non-null  bool  \n",
      " 3   Sales Organisation  252265 non-null  object\n",
      "dtypes: bool(1), int64(1), object(2)\n",
      "memory usage: 6.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df21.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3['Serial ID'] = df3['Serial ID'].astype('str')\n",
    "df21['Serial ID'] = df21['Serial ID'].astype('str')\n",
    "df3['index'] = df3['index'].astype('str')\n",
    "df21['index'] = df21['index'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3['KeyIndSer'] = df3['index'] + \"-\" + df3['Serial ID']\n",
    "df21['KeyIndSer'] = df21['index'] + \"-\" + df21['Serial ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = pd.merge(df3, df21, how='left', left_on = ['KeyIndSer'], right_on = ['KeyIndSer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index_x</th>\n",
       "      <th>Serial ID_x</th>\n",
       "      <th>False</th>\n",
       "      <th>True</th>\n",
       "      <th>KeyIndSer</th>\n",
       "      <th>index_y</th>\n",
       "      <th>Serial ID_y</th>\n",
       "      <th>Churn</th>\n",
       "      <th>Sales Organisation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>TH10127992</td>\n",
       "      <td>0.999143</td>\n",
       "      <td>0.000857</td>\n",
       "      <td>0-TH10127992</td>\n",
       "      <td>0</td>\n",
       "      <td>TH10127992</td>\n",
       "      <td>False</td>\n",
       "      <td>Thailand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>TH10213045</td>\n",
       "      <td>0.461446</td>\n",
       "      <td>0.538554</td>\n",
       "      <td>1-TH10213045</td>\n",
       "      <td>1</td>\n",
       "      <td>TH10213045</td>\n",
       "      <td>False</td>\n",
       "      <td>Thailand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>TH10212610</td>\n",
       "      <td>0.872295</td>\n",
       "      <td>0.127705</td>\n",
       "      <td>2-TH10212610</td>\n",
       "      <td>2</td>\n",
       "      <td>TH10212610</td>\n",
       "      <td>False</td>\n",
       "      <td>Thailand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>TH10213000</td>\n",
       "      <td>0.857011</td>\n",
       "      <td>0.142989</td>\n",
       "      <td>3-TH10213000</td>\n",
       "      <td>3</td>\n",
       "      <td>TH10213000</td>\n",
       "      <td>False</td>\n",
       "      <td>Thailand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>TH10108148</td>\n",
       "      <td>0.897466</td>\n",
       "      <td>0.102534</td>\n",
       "      <td>4-TH10108148</td>\n",
       "      <td>4</td>\n",
       "      <td>TH10108148</td>\n",
       "      <td>False</td>\n",
       "      <td>Thailand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252260</th>\n",
       "      <td>252260</td>\n",
       "      <td>20O0017852</td>\n",
       "      <td>0.074047</td>\n",
       "      <td>0.925953</td>\n",
       "      <td>252260-20O0017852</td>\n",
       "      <td>252260</td>\n",
       "      <td>20O0017852</td>\n",
       "      <td>True</td>\n",
       "      <td>Singapore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252261</th>\n",
       "      <td>252261</td>\n",
       "      <td>20O0017851</td>\n",
       "      <td>0.097694</td>\n",
       "      <td>0.902306</td>\n",
       "      <td>252261-20O0017851</td>\n",
       "      <td>252261</td>\n",
       "      <td>20O0017851</td>\n",
       "      <td>True</td>\n",
       "      <td>Singapore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252262</th>\n",
       "      <td>252262</td>\n",
       "      <td>20O0017860</td>\n",
       "      <td>0.009865</td>\n",
       "      <td>0.990135</td>\n",
       "      <td>252262-20O0017860</td>\n",
       "      <td>252262</td>\n",
       "      <td>20O0017860</td>\n",
       "      <td>True</td>\n",
       "      <td>Singapore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252263</th>\n",
       "      <td>252263</td>\n",
       "      <td>20O0017861</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>252263-20O0017861</td>\n",
       "      <td>252263</td>\n",
       "      <td>20O0017861</td>\n",
       "      <td>True</td>\n",
       "      <td>Singapore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252264</th>\n",
       "      <td>252264</td>\n",
       "      <td>20O0017862</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>252264-20O0017862</td>\n",
       "      <td>252264</td>\n",
       "      <td>20O0017862</td>\n",
       "      <td>True</td>\n",
       "      <td>Singapore</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>252265 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index_x Serial ID_x     False      True          KeyIndSer index_y  \\\n",
       "0            0  TH10127992  0.999143  0.000857       0-TH10127992       0   \n",
       "1            1  TH10213045  0.461446  0.538554       1-TH10213045       1   \n",
       "2            2  TH10212610  0.872295  0.127705       2-TH10212610       2   \n",
       "3            3  TH10213000  0.857011  0.142989       3-TH10213000       3   \n",
       "4            4  TH10108148  0.897466  0.102534       4-TH10108148       4   \n",
       "...        ...         ...       ...       ...                ...     ...   \n",
       "252260  252260  20O0017852  0.074047  0.925953  252260-20O0017852  252260   \n",
       "252261  252261  20O0017851  0.097694  0.902306  252261-20O0017851  252261   \n",
       "252262  252262  20O0017860  0.009865  0.990135  252262-20O0017860  252262   \n",
       "252263  252263  20O0017861  0.000000  1.000000  252263-20O0017861  252263   \n",
       "252264  252264  20O0017862  0.000000  1.000000  252264-20O0017862  252264   \n",
       "\n",
       "       Serial ID_y  Churn Sales Organisation  \n",
       "0       TH10127992  False           Thailand  \n",
       "1       TH10213045  False           Thailand  \n",
       "2       TH10212610  False           Thailand  \n",
       "3       TH10213000  False           Thailand  \n",
       "4       TH10108148  False           Thailand  \n",
       "...            ...    ...                ...  \n",
       "252260  20O0017852   True          Singapore  \n",
       "252261  20O0017851   True          Singapore  \n",
       "252262  20O0017860   True          Singapore  \n",
       "252263  20O0017861   True          Singapore  \n",
       "252264  20O0017862   True          Singapore  \n",
       "\n",
       "[252265 rows x 9 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.to_csv(r'C:\\Users\\msalomo\\predictions-Churn-RandomForest2.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'#months of data', 'Depreciation Start',\n",
    "       'Industry (EC ID)_0614 InStore Food Service',\n",
    "       'End Date in Local Time Zone_x', \n",
    "       'G/R/M TB_MTB (Market)', 'Position_#', 'Position_LOAN',\n",
    "       'Incident Category_New Customer / Installation Point',\n",
    "       'User Status_Installed', 'Model Group_Other',\n",
    "       'User Status_To be removed', 'Service Category_Installation.',\n",
    "       'Last_visit_diff_months', 'Model Vendor_SAI Vending',\n",
    "       'Trading Partner_Direct', 'End Date in Local Time Zone_y',\n",
    "       'Industry (EC ID)_0614 Convenience OOH',\n",
    "       'System Brands_Nescafé Branded'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest generally outperforms Decision Tree for accuracy, which is the case. \n",
    "I am focusing on the F1_macro score, and here Random Forest also outperforms decision tree for F1_macro."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
