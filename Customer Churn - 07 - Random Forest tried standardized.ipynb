{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone proposal by Mirko Salomon \n",
    "\n",
    "# BEVERAGE MACHINE CHURN PREDICTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ## [1) Introduction and preparation](#Introduction) \n",
    "\n",
    "    *   \n",
    "        #### Data Load\n",
    "        \n",
    "        #### Hyperparameters\n",
    "        \n",
    "* ## [2) Random Forest model](#RF)\n",
    "    \n",
    "    *   \n",
    "        #### Train the model\n",
    "        \n",
    "        #### Test data with best parameters \n",
    "        \n",
    "        #### Confusion Matrix\n",
    "        \n",
    "        #### Tree Plot\n",
    "        \n",
    "        #### Prediction of churn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Introduction and preparation<a class=\"anchor\" id=\"Introduction\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forests are an ensemble learning method for classification that operate by constructing a multitude of decision trees at training time and outputting the class that is the mode of the classes (classification) or mean/average prediction (regression) of the individual trees.\n",
    "\n",
    "Based on the flowchart from Scikit Learn I should try a Random Forest model.\n",
    "\n",
    "This model is a bit more a black box than a regression or decision tree\n",
    "\n",
    "Has predict_proba that predicts class probabilities for X, can handle well categorical features, maintains accuracy when the data is missing\n",
    "\n",
    "Seems to have good Performance on Imbalanced datasets and we can also modify the weights\n",
    "\n",
    "Is a model working differently than a regression model and performs usually better than a decision tree\n",
    "\n",
    "I will tune the number of estimators and the maximum number of features. I will also tune the class weigth and the bootstrap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "import xlrd\n",
    "\n",
    "import datetime as dt\n",
    "from datetime import datetime\n",
    "\n",
    "import collections\n",
    "from collections import Counter\n",
    "\n",
    "# Import seaborn\n",
    "import seaborn as sns\n",
    "\n",
    "# Specify the file path\n",
    "file_path = r'C:\\Users\\msalomo\\OneDrive - NESTLE\\Certificate Machine Learning and Data\\Churn Project\\Notebook output'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conda update -c conda-forge scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install --upgrade scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#libraries\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Import Random Forest Model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "from sklearn import metrics \n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#from sklearn.metrics import plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the filename\n",
    "filename = 'BM_noTickets_preprocess.p'\n",
    "\n",
    "# Combine the file path and filename\n",
    "file_path_with_filename = os.path.join(file_path, filename)\n",
    "\n",
    "# Load the pickle file\n",
    "with open(file_path_with_filename, 'rb') as file:\n",
    "    BM_noTickets_preprocess = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pickle file 'X.p'\n",
    "with open(os.path.join(file_path, 'X.p'), 'rb') as file:\n",
    "    X = pickle.load(file)\n",
    "\n",
    "# Load the pickle file 'y.p'\n",
    "with open(os.path.join(file_path, 'y.p'), 'rb') as file:\n",
    "    y = pickle.load(file)\n",
    "\n",
    "# Load the pickle file 'X_tr.p'\n",
    "with open(os.path.join(file_path, 'X_tr.p'), 'rb') as file:\n",
    "    X_tr = pickle.load(file)\n",
    "\n",
    "# Load the pickle file 'y_tr.p'\n",
    "with open(os.path.join(file_path, 'y_tr.p'), 'rb') as file:\n",
    "    y_tr = pickle.load(file)\n",
    "\n",
    "# Load the pickle file 'X_val.p'\n",
    "with open(os.path.join(file_path, 'X_val.p'), 'rb') as file:\n",
    "    X_val = pickle.load(file)\n",
    "\n",
    "# Load the pickle file 'y_val.p'\n",
    "with open(os.path.join(file_path, 'y_val.p'), 'rb') as file:\n",
    "    y_val = pickle.load(file)\n",
    "\n",
    "# Load the pickle file 'X_te.p'\n",
    "with open(os.path.join(file_path, 'X_te.p'), 'rb') as file:\n",
    "    X_te = pickle.load(file)\n",
    "\n",
    "# Load the pickle file 'y_te.p'\n",
    "with open(os.path.join(file_path, 'y_te.p'), 'rb') as file:\n",
    "    y_te = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TA Contract Installation Date</th>\n",
       "      <th>Depreciation Start</th>\n",
       "      <th>TA Contract Start Date</th>\n",
       "      <th>TA Contract End Date</th>\n",
       "      <th>Churn</th>\n",
       "      <th>Service Category_Installation</th>\n",
       "      <th>Service Category_Removal</th>\n",
       "      <th>Service Category_Replacement</th>\n",
       "      <th>INCIDENT_CATEGORY_DESCRIPTION_Customer relocation</th>\n",
       "      <th>INCIDENT_CATEGORY_DESCRIPTION_Exchange / Replacement Sales</th>\n",
       "      <th>...</th>\n",
       "      <th>Generation_Gen. 2</th>\n",
       "      <th>Generation_Legacy</th>\n",
       "      <th>Blueprint Throughput_%23-N/A</th>\n",
       "      <th>Blueprint Throughput_High</th>\n",
       "      <th>Blueprint Throughput_Low</th>\n",
       "      <th>Blueprint Throughput_Medium</th>\n",
       "      <th>IP Ownership_Exclusive</th>\n",
       "      <th>IP Ownership_Non-Proprietary</th>\n",
       "      <th>IP Ownership_Propr. Comp.</th>\n",
       "      <th>IP Ownership_Proprietary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1824.0</td>\n",
       "      <td>2252.0</td>\n",
       "      <td>1809.0</td>\n",
       "      <td>59.366176</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1824.0</td>\n",
       "      <td>2252.0</td>\n",
       "      <td>1809.0</td>\n",
       "      <td>59.366176</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1824.0</td>\n",
       "      <td>2252.0</td>\n",
       "      <td>1809.0</td>\n",
       "      <td>59.366176</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1824.0</td>\n",
       "      <td>2252.0</td>\n",
       "      <td>1809.0</td>\n",
       "      <td>59.366176</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1824.0</td>\n",
       "      <td>5052.0</td>\n",
       "      <td>1809.0</td>\n",
       "      <td>59.366176</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1372 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   TA Contract Installation Date  Depreciation Start  TA Contract Start Date  \\\n",
       "0                         1824.0              2252.0                  1809.0   \n",
       "1                         1824.0              2252.0                  1809.0   \n",
       "2                         1824.0              2252.0                  1809.0   \n",
       "3                         1824.0              2252.0                  1809.0   \n",
       "4                         1824.0              5052.0                  1809.0   \n",
       "\n",
       "   TA Contract End Date  Churn  Service Category_Installation  \\\n",
       "0             59.366176  False                            0.0   \n",
       "1             59.366176  False                            0.0   \n",
       "2             59.366176  False                            0.0   \n",
       "3             59.366176  False                            0.0   \n",
       "4             59.366176  False                            0.0   \n",
       "\n",
       "   Service Category_Removal  Service Category_Replacement  \\\n",
       "0                       0.0                           0.0   \n",
       "1                       0.0                           0.0   \n",
       "2                       0.0                           0.0   \n",
       "3                       0.0                           0.0   \n",
       "4                       0.0                           0.0   \n",
       "\n",
       "   INCIDENT_CATEGORY_DESCRIPTION_Customer relocation  \\\n",
       "0                                                0.0   \n",
       "1                                                0.0   \n",
       "2                                                0.0   \n",
       "3                                                0.0   \n",
       "4                                                0.0   \n",
       "\n",
       "   INCIDENT_CATEGORY_DESCRIPTION_Exchange / Replacement Sales  ...  \\\n",
       "0                                                0.0           ...   \n",
       "1                                                0.0           ...   \n",
       "2                                                0.0           ...   \n",
       "3                                                0.0           ...   \n",
       "4                                                0.0           ...   \n",
       "\n",
       "   Generation_Gen. 2  Generation_Legacy  Blueprint Throughput_%23-N/A  \\\n",
       "0                  0                  1                             0   \n",
       "1                  0                  0                             0   \n",
       "2                  0                  1                             0   \n",
       "3                  0                  0                             0   \n",
       "4                  0                  1                             0   \n",
       "\n",
       "   Blueprint Throughput_High  Blueprint Throughput_Low  \\\n",
       "0                          0                         0   \n",
       "1                          0                         1   \n",
       "2                          0                         0   \n",
       "3                          0                         1   \n",
       "4                          0                         0   \n",
       "\n",
       "   Blueprint Throughput_Medium  IP Ownership_Exclusive  \\\n",
       "0                            1                       0   \n",
       "1                            0                       0   \n",
       "2                            1                       0   \n",
       "3                            0                       0   \n",
       "4                            1                       0   \n",
       "\n",
       "   IP Ownership_Non-Proprietary  IP Ownership_Propr. Comp.  \\\n",
       "0                             1                          0   \n",
       "1                             1                          0   \n",
       "2                             1                          0   \n",
       "3                             1                          0   \n",
       "4                             1                          0   \n",
       "\n",
       "   IP Ownership_Proprietary  \n",
       "0                         0  \n",
       "1                         0  \n",
       "2                         0  \n",
       "3                         0  \n",
       "4                         0  \n",
       "\n",
       "[5 rows x 1372 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BM_noTickets_preprocess.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 242251 entries, 0 to 242250\n",
      "Columns: 1372 entries, TA Contract Installation Date to IP Ownership_Proprietary\n",
      "dtypes: bool(1), float64(102), int32(2), int64(2), object(1), uint8(1264)\n",
      "memory usage: 490.0+ MB\n"
     ]
    }
   ],
   "source": [
    "BM_noTickets_preprocess.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class sklearn.ensemble.RandomForestClassifier(n_estimators=100, *, criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='auto', max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, bootstrap=True, oob_score=False, n_jobs=None, random_state=None, verbose=0, warm_start=False, class_weight=None, ccp_alpha=0.0, max_samples=None)\n",
    "\n",
    "---\n",
    "\n",
    "The number of trees in the forest. I will try some.\n",
    "\n",
    "n_estimators = range(20,200,20)\n",
    "\n",
    "---\n",
    "\n",
    "The maximum depth of the tree. I will try some.\n",
    "\n",
    "max_depth = (20, 50, 100, None)\n",
    "\n",
    "---\n",
    "\n",
    "The function to measure the quality of a split. I will try both.\n",
    "\n",
    "criterion = ('gini', 'entropy')\n",
    "\n",
    "---\n",
    "\n",
    "Whether bootstrap samples are used when building trees. If False, the whole dataset is used to build each tree.\n",
    "I will try both.\n",
    "\n",
    "bootstrap = (True, False)\n",
    "\n",
    "---\n",
    "\n",
    "Weights associated with classes in the form.\n",
    "\n",
    "class_weight = ('balanced', None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Random Forest model<a class=\"anchor\" id=\"RF\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(135660,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(135660, 1371)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48451, 1371)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(X_te)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# Define a set of reasonable values\n",
    "#n_estimators = range(20,160,20) # I tried till 200 but it was not in the top results, so I reduced to 160\n",
    "n_estimators = range(20,120,60) # I tried till 200 but it was not in the top results, so I reduced to 160\n",
    "\n",
    "#max_depth = (20, 50, 10, None) # I tried with 200, 300, but results were not better\n",
    "max_depth = (20, 50, None) # I tried with 200, 300, but results were not better\n",
    "\n",
    "criterion = ('gini', 'entropy')\n",
    "#bootstrap = (True, False)\n",
    "bootstrap = (True)\n",
    "class_weight = ('balanced', None) # I tried with  'balanced_subsample', but I had lower scores.\n",
    "\n",
    "\n",
    "# Define a parameter grid of values\n",
    "grid = ParameterGrid({'rf__n_estimators' : n_estimators,\n",
    "                    'rf__max_depth' : max_depth,\n",
    "                    'rf__criterion' :  criterion,\n",
    "                    'rf__bootstrap' : (True, False),\n",
    "                    'rf__class_weight' : class_weight \n",
    "                   }\n",
    "                  )\n",
    " \n",
    "\n",
    "# Create pipeline, random forest classifier\n",
    "pipe = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('rf', RandomForestClassifier(random_state=1))\n",
    "    ]\n",
    ")\n",
    "   \n",
    "# Save accuracy on test set\n",
    "test_scores = []\n",
    "\n",
    "for params_dict in grid:\n",
    "    # Set parameters\n",
    "    pipe.set_params(**params_dict)\n",
    "\n",
    "    # Fit a k-NN classifier\n",
    "    pipe.fit(X_tr, y_tr)\n",
    "\n",
    "    # Save accuracy on validation set\n",
    "    params_dict['accuracy'] = pipe.score(X_val, y_val)\n",
    "    # Save f1 score on validation set\n",
    "    # predict test instances\n",
    "    y_pred = pipe.predict(X_val)\n",
    "    params_dict['f1_macro'] = metrics.f1_score(y_val, y_pred, average='macro')\n",
    "    \n",
    "    # Save result\n",
    "    test_scores.append(params_dict)\n",
    "    \n",
    "# Create DataFrame with test scores\n",
    "scores_df = pd.DataFrame(test_scores)\n",
    "\n",
    "# Top five scores\n",
    "scores_df.sort_values(by='f1_macro', ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "rf = RandomForestClassifier(random_state=1)\n",
    "rf.fit(X_tr, y_tr)\n",
    "y_pred = rf.predict(X_te) # Predictions\n",
    "y_true = y_te # True values\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Train accuracy:\", np.round(accuracy_score(y_tr, \n",
    "                                                 rfc.predict(X_tr)), 2))\n",
    "print(\"Test accuracy:\", np.round(accuracy_score(y_true, y_pred), 2))\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cf_matrix = confusion_matrix(y_true, y_pred)\n",
    "print(\"\\nTest confusion_matrix\")\n",
    "sns.heatmap(cf_matrix, annot=True, cmap='Blues')\n",
    "plt.xlabel('Predicted', fontsize=12)\n",
    "plt.ylabel('True', fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "estimator.get_params().keys()\n",
    "param = {'rf__n_estimators' : n_estimators,\n",
    "         'rf__max_depth' : max_depth,\n",
    "         'rf__criterion' :  criterion,\n",
    "         'rf__bootstrap' : (True, False),\n",
    "         'rf__class_weight' : class_weight \n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's measure execution time too\n",
    "import time\n",
    "start = time.time()\n",
    "\n",
    "# Define a set of reasonable values\n",
    "n_estimators = range(20,160,20) # I tried till 200 but it was not in the top results, so I reduced to 160\n",
    "max_depth = (20, 50, 10, None) # I tried with 200, 300, but results were not better\n",
    "criterion = ('gini', 'entropy')\n",
    "bootstrap = (True, False)\n",
    "class_weight = ('balanced', None) # I tried with  'balanced_subsample', but I had lower scores.\n",
    "\n",
    "\n",
    "# Defining 3-dimensional hyperparameter space as a Python dictionary\n",
    "#hyperparameter_space = {'rf__n_estimators' : n_estimators, 'rf__max_depth' : max_depth,\n",
    "#                    'rf__criterion' :  criterion,\n",
    "#                    'rf__bootstrap' : (True, False),\n",
    "#                    'rf__class_weight' : class_weight \n",
    "\n",
    "#param = {'rf__n_estimators' : n_estimators,\n",
    "#         'rf__max_depth' : max_depth,\n",
    "#         'rf__max_depth' : max_depth,\n",
    "#         'rf__criterion' :  criterion,\n",
    "#         'rf__bootstrap' : (True, False),\n",
    "#         'rf__class_weight' : class_weight \n",
    "#        }\n",
    "\n",
    "random_grid = {'bootstrap': [True, False],\n",
    "               'max_depth': [10, None],\n",
    "               'min_samples_leaf': [1, 4],\n",
    "               'min_samples_split': [2, 5],\n",
    "               'n_estimators': [130, 230]}\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "#rs = RandomizedSearchCV(rfc, param_distributions=hyperparameter_space,\n",
    "#                        n_iter=10, scoring= 'f1_macro', random_state=1,\n",
    "#                        n_jobs=-1, cv=10, return_train_score=True)\n",
    "\n",
    "\n",
    "#rs = RandomizedSearchCV(rf, param, n_iter =10, cv=9)\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, verbose=2, random_state=42, n_jobs = -1)\n",
    "\n",
    "rf_random.fit(X_tr, y_tr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#rs.fit(X_tr, y_tr)\n",
    "print(\"Optimal hyperparameter combination:\", rs.best_params_)\n",
    "print()\n",
    "print(\"Mean cross-validated training accuracy score:\",\n",
    "      rs.best_score_)\n",
    "rs.best_estimator_.fit(X_tr, y_tr)\n",
    "y_pred = rs.best_estimator_.predict(X_te) # Predictions\n",
    "y_true = y_te # True values\n",
    "\n",
    "print(\"Test accuracy:\", np.round(accuracy_score(y_true, y_pred), 2))\n",
    "cf_matrix = confusion_matrix(y_true, y_pred)\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.heatmap(cf_matrix, annot=True, cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "\n",
    "end = time.time()\n",
    "diff = end - start\n",
    "print('Execution time of Random Search (in Seconds):', diff)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cv_results = rf_random.cv_results_\n",
    "for mean_score, params in zip(cv_results[\"mean_test_score\"], cvres[\"params\"]):\n",
    "    print(np.sqrt(-mean_score), params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rf__n_estimators</th>\n",
       "      <th>rf__max_depth</th>\n",
       "      <th>rf__criterion</th>\n",
       "      <th>rf__bootstrap</th>\n",
       "      <th>rf__class_weight</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>80</td>\n",
       "      <td>50</td>\n",
       "      <td>entropy</td>\n",
       "      <td>False</td>\n",
       "      <td>balanced</td>\n",
       "      <td>0.875317</td>\n",
       "      <td>0.863325</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rf__n_estimators  rf__max_depth rf__criterion  rf__bootstrap  \\\n",
       "0                80             50       entropy          False   \n",
       "\n",
       "  rf__class_weight  accuracy  f1_macro  \n",
       "0         balanced  0.875317  0.863325  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_dict = {'rf__n_estimators': 80, \n",
    " 'rf__max_depth': 50, \n",
    " 'rf__criterion': 'entropy', \n",
    " 'rf__bootstrap': False, \n",
    " 'rf__class_weight': 'balanced'}\n",
    "\n",
    "# Create pipeline, random forest classifier\n",
    "pipe = Pipeline([\n",
    "    #('oversample', SmoteSample_model),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('rf', RandomForestClassifier(random_state=1))\n",
    "    ]\n",
    ")\n",
    "  \n",
    "# Save accuracy on test set\n",
    "test_scores = []\n",
    "\n",
    "# Set parameters\n",
    "pipe.set_params(**params_dict)\n",
    "\n",
    "# Fit a k-NN classifier\n",
    "pipe.fit(X_tr, y_tr)\n",
    "\n",
    "# Save accuracy on validation set\n",
    "params_dict['accuracy'] = pipe.score(X_te, y_te)\n",
    "# Save f1 score on validation set\n",
    "# predict test instances\n",
    "y_pred = pipe.predict(X_te)\n",
    "params_dict['f1_macro'] = metrics.f1_score(y_te, y_pred, average='macro')\n",
    "    \n",
    "# Save result\n",
    "test_scores.append(params_dict)\n",
    "    \n",
    "# Create DataFrame with test scores\n",
    "scores_df = pd.DataFrame(test_scores)\n",
    "\n",
    "# Top five scores\n",
    "scores_df.sort_values(by='f1_macro', ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have an F1 Macro score of 83.8% and an accuracy of 93.7% with the test data. Which is close to the validation data results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('database or disk is full')).History will not be written to the database.\n"
     ]
    }
   ],
   "source": [
    "# F1_score\n",
    "RF_F1Macro = params_dict['f1_macro']\n",
    "\n",
    "# Accuracy\n",
    "RF_accuracy = params_dict['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_Results: [0.52320282 0.         0.         0.         0.86332485 0.\n",
      " 0.         0.        ]\n",
      "Accuracy: [0.6396772  0.         0.         0.         0.87531733 0.\n",
      " 0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "# Specify the filename\n",
    "filename = 'Results.npz'\n",
    "\n",
    "# Combine the file path and filename\n",
    "file_path_with_filename = os.path.join(file_path, filename)\n",
    "\n",
    "# Load the npz file for results\n",
    "with np.load(file_path_with_filename, allow_pickle=False) as npz_file:\n",
    "    F1Score = npz_file['test_F1Score']\n",
    "    accuracy = npz_file['test_accuracy']\n",
    "    models = npz_file['models']\n",
    "    \n",
    "# Fill the calculated result value\n",
    "F1Score[4] = RF_F1Macro\n",
    "accuracy[4] = RF_accuracy\n",
    "\n",
    "print('F1_Results:', F1Score)\n",
    "print('Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify the Numpy array\n",
    "#Model = models #unchanged\n",
    "Result = F1Score\n",
    "Accuracy = accuracy\n",
    "\n",
    "# Specify the filename\n",
    "filename = 'Results.npz'\n",
    "\n",
    "# Combine the file path and filename\n",
    "file_path_with_filename = os.path.join(file_path, filename)\n",
    "\n",
    "# Store the changes in the results npz file\n",
    "np.savez(file_path_with_filename, models=models, test_F1Score=Result, test_accuracy=Accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['models', 'test_F1Score', 'test_accuracy']\n",
      "Models: ['Baseline' 'Logistic Regression' 'KNeighbors' 'Decision Tree'\n",
      " 'Random Forest' 'XGBoost' 'SelectedModel_wTickets'\n",
      " 'SelectedModel_wTickets&Telemetry']\n",
      "F1_Results: [0.52320282 0.         0.         0.         0.86332485 0.\n",
      " 0.         0.        ]\n",
      "Accuracy: [0.6396772  0.         0.         0.         0.87531733 0.\n",
      " 0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "# Check the refreshed results\n",
    "# Specify the filename\n",
    "filename = 'Results.npz'\n",
    "\n",
    "# Combine the file path and filename\n",
    "file_path_with_filename = os.path.join(file_path, filename)\n",
    "\n",
    "# Load the npz file for results\n",
    "with np.load(file_path_with_filename, allow_pickle=False) as npz_file:\n",
    "    # It's a dictionary-like object\n",
    "    print(list(npz_file.keys()))\n",
    "    # Load the arrays\n",
    "    print('Models:', npz_file['models'])\n",
    "    print('F1_Results:', npz_file['test_F1Score'])\n",
    "    print('Accuracy:', npz_file['test_accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[28381  2603]\n",
      " [ 3438 14029]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False      0.892     0.916     0.904     30984\n",
      "        True      0.843     0.803     0.823     17467\n",
      "\n",
      "    accuracy                          0.875     48451\n",
      "   macro avg      0.868     0.860     0.863     48451\n",
      "weighted avg      0.874     0.875     0.875     48451\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Classification reports and confusion matrices are commonly used for reporting the performance of classifiers when working with imbalanced datasets.\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(metrics.confusion_matrix(y_te, y_pred))\n",
    "\n",
    "# Print the precision and recall, among other metrics\n",
    "print(metrics.classification_report(y_te, y_pred, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>False Condition</th>\n",
       "      <th>True Condition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Predicted False</th>\n",
       "      <td>28381</td>\n",
       "      <td>3438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predicted True</th>\n",
       "      <td>2603</td>\n",
       "      <td>14029</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 False Condition  True Condition\n",
       "Predicted False            28381            3438\n",
       "Predicted True              2603           14029"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Classification reports and confusion matrices are commonly used for reporting the performance of classifiers when working with imbalanced datasets.\n",
    "ConfMat_df = pd.DataFrame(metrics.confusion_matrix(y_te, y_pred).T, columns=['False Condition', 'True Condition'],index=['Predicted False', 'Predicted True'])\n",
    "ConfMat_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a good F1 Score for the False Condition but not as good for the True Condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the filename\n",
    "filename = 'Random Forest_ConfMat_df.p'\n",
    "\n",
    "# Combine the file path and filename\n",
    "file_path_with_filename = os.path.join(file_path, filename)\n",
    "\n",
    "# Save the DataFrame into a pickle file\n",
    "with open(file_path_with_filename, 'wb') as file:\n",
    "    pickle.dump(ConfMat_df, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction of churn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Churn prediction from the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the filename\n",
    "filename = 'BeverageMachine_withSerial.p'\n",
    "\n",
    "# Combine the file path and filename\n",
    "file_path_with_filename = os.path.join(file_path, filename)\n",
    "\n",
    "# Load the pickle file\n",
    "with open(file_path_with_filename, 'rb') as file:\n",
    "    BeverageMachine_withSerial = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "name = ['False', 'True']\n",
    "No=BeverageMachine_withSerial['Serial ID']\n",
    "predictions = pipe.predict_proba(X)\n",
    "# With two column indices, values same  \n",
    "# as dictionary keys \n",
    "df2 = pd.DataFrame(predictions, index=No ,columns = name) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial ID</th>\n",
       "      <th>False</th>\n",
       "      <th>True</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Y0302794</td>\n",
       "      <td>0.996717</td>\n",
       "      <td>0.003283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Y1108983</td>\n",
       "      <td>0.945893</td>\n",
       "      <td>0.054107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Y0403242</td>\n",
       "      <td>0.996717</td>\n",
       "      <td>0.003283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Y1108995</td>\n",
       "      <td>0.945893</td>\n",
       "      <td>0.054107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AU4072</td>\n",
       "      <td>0.416496</td>\n",
       "      <td>0.583504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242246</th>\n",
       "      <td>20O0017852</td>\n",
       "      <td>0.095908</td>\n",
       "      <td>0.904092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242247</th>\n",
       "      <td>20O0017851</td>\n",
       "      <td>0.164426</td>\n",
       "      <td>0.835574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242248</th>\n",
       "      <td>20O0017860</td>\n",
       "      <td>0.089723</td>\n",
       "      <td>0.910277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242249</th>\n",
       "      <td>20O0017861</td>\n",
       "      <td>0.016748</td>\n",
       "      <td>0.983252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242250</th>\n",
       "      <td>20O0017862</td>\n",
       "      <td>0.024889</td>\n",
       "      <td>0.975111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>242251 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Serial ID     False      True\n",
       "0         Y0302794  0.996717  0.003283\n",
       "1         Y1108983  0.945893  0.054107\n",
       "2         Y0403242  0.996717  0.003283\n",
       "3         Y1108995  0.945893  0.054107\n",
       "4           AU4072  0.416496  0.583504\n",
       "...            ...       ...       ...\n",
       "242246  20O0017852  0.095908  0.904092\n",
       "242247  20O0017851  0.164426  0.835574\n",
       "242248  20O0017860  0.089723  0.910277\n",
       "242249  20O0017861  0.016748  0.983252\n",
       "242250  20O0017862  0.024889  0.975111\n",
       "\n",
       "[242251 rows x 3 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3 = df2.reset_index(level=None)\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 242251 entries, 0 to 242250\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count   Dtype  \n",
      "---  ------     --------------   -----  \n",
      " 0   index      242251 non-null  int64  \n",
      " 1   Serial ID  242251 non-null  object \n",
      " 2   False      242251 non-null  float64\n",
      " 3   True       242251 non-null  float64\n",
      "dtypes: float64(2), int64(1), object(1)\n",
      "memory usage: 7.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df3.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Serial ID</th>\n",
       "      <th>Churn</th>\n",
       "      <th>Sales Organisation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Y0302794</td>\n",
       "      <td>False</td>\n",
       "      <td>NP-France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Y1108983</td>\n",
       "      <td>False</td>\n",
       "      <td>NP-France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Y0403242</td>\n",
       "      <td>False</td>\n",
       "      <td>NP-France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Y1108995</td>\n",
       "      <td>False</td>\n",
       "      <td>NP-France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>AU4072</td>\n",
       "      <td>False</td>\n",
       "      <td>Nestle Australia Ltd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242246</th>\n",
       "      <td>242246</td>\n",
       "      <td>20O0017852</td>\n",
       "      <td>True</td>\n",
       "      <td>Singapore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242247</th>\n",
       "      <td>242247</td>\n",
       "      <td>20O0017851</td>\n",
       "      <td>True</td>\n",
       "      <td>Singapore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242248</th>\n",
       "      <td>242248</td>\n",
       "      <td>20O0017860</td>\n",
       "      <td>True</td>\n",
       "      <td>Singapore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242249</th>\n",
       "      <td>242249</td>\n",
       "      <td>20O0017861</td>\n",
       "      <td>True</td>\n",
       "      <td>Singapore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242250</th>\n",
       "      <td>242250</td>\n",
       "      <td>20O0017862</td>\n",
       "      <td>True</td>\n",
       "      <td>Singapore</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>242251 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         index   Serial ID  Churn    Sales Organisation\n",
       "0            0    Y0302794  False             NP-France\n",
       "1            1    Y1108983  False             NP-France\n",
       "2            2    Y0403242  False             NP-France\n",
       "3            3    Y1108995  False             NP-France\n",
       "4            4      AU4072  False  Nestle Australia Ltd\n",
       "...        ...         ...    ...                   ...\n",
       "242246  242246  20O0017852   True             Singapore\n",
       "242247  242247  20O0017851   True             Singapore\n",
       "242248  242248  20O0017860   True             Singapore\n",
       "242249  242249  20O0017861   True             Singapore\n",
       "242250  242250  20O0017862   True             Singapore\n",
       "\n",
       "[242251 rows x 4 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df21 = pd.DataFrame(BeverageMachine_withSerial[['Serial ID','Churn', 'Sales Organisation']]).reset_index(level=None)\n",
    "df21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 242251 entries, 0 to 242250\n",
      "Data columns (total 4 columns):\n",
      " #   Column              Non-Null Count   Dtype \n",
      "---  ------              --------------   ----- \n",
      " 0   index               242251 non-null  int64 \n",
      " 1   Serial ID           242251 non-null  object\n",
      " 2   Churn               242251 non-null  bool  \n",
      " 3   Sales Organisation  242251 non-null  object\n",
      "dtypes: bool(1), int64(1), object(2)\n",
      "memory usage: 5.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df21.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3['Serial ID'] = df3['Serial ID'].astype('str')\n",
    "df21['Serial ID'] = df21['Serial ID'].astype('str')\n",
    "df3['index'] = df3['index'].astype('str')\n",
    "df21['index'] = df21['index'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3['KeyIndSer'] = df3['index'] + \"-\" + df3['Serial ID']\n",
    "df21['KeyIndSer'] = df21['index'] + \"-\" + df21['Serial ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = pd.merge(df3, df21, how='left', left_on = ['KeyIndSer'], right_on = ['KeyIndSer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index_x</th>\n",
       "      <th>Serial ID_x</th>\n",
       "      <th>False</th>\n",
       "      <th>True</th>\n",
       "      <th>KeyIndSer</th>\n",
       "      <th>index_y</th>\n",
       "      <th>Serial ID_y</th>\n",
       "      <th>Churn</th>\n",
       "      <th>Sales Organisation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Y0302794</td>\n",
       "      <td>0.996717</td>\n",
       "      <td>0.003283</td>\n",
       "      <td>0-Y0302794</td>\n",
       "      <td>0</td>\n",
       "      <td>Y0302794</td>\n",
       "      <td>False</td>\n",
       "      <td>NP-France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Y1108983</td>\n",
       "      <td>0.945893</td>\n",
       "      <td>0.054107</td>\n",
       "      <td>1-Y1108983</td>\n",
       "      <td>1</td>\n",
       "      <td>Y1108983</td>\n",
       "      <td>False</td>\n",
       "      <td>NP-France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Y0403242</td>\n",
       "      <td>0.996717</td>\n",
       "      <td>0.003283</td>\n",
       "      <td>2-Y0403242</td>\n",
       "      <td>2</td>\n",
       "      <td>Y0403242</td>\n",
       "      <td>False</td>\n",
       "      <td>NP-France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Y1108995</td>\n",
       "      <td>0.945893</td>\n",
       "      <td>0.054107</td>\n",
       "      <td>3-Y1108995</td>\n",
       "      <td>3</td>\n",
       "      <td>Y1108995</td>\n",
       "      <td>False</td>\n",
       "      <td>NP-France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>AU4072</td>\n",
       "      <td>0.416496</td>\n",
       "      <td>0.583504</td>\n",
       "      <td>4-AU4072</td>\n",
       "      <td>4</td>\n",
       "      <td>AU4072</td>\n",
       "      <td>False</td>\n",
       "      <td>Nestle Australia Ltd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242246</th>\n",
       "      <td>242246</td>\n",
       "      <td>20O0017852</td>\n",
       "      <td>0.095908</td>\n",
       "      <td>0.904092</td>\n",
       "      <td>242246-20O0017852</td>\n",
       "      <td>242246</td>\n",
       "      <td>20O0017852</td>\n",
       "      <td>True</td>\n",
       "      <td>Singapore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242247</th>\n",
       "      <td>242247</td>\n",
       "      <td>20O0017851</td>\n",
       "      <td>0.164426</td>\n",
       "      <td>0.835574</td>\n",
       "      <td>242247-20O0017851</td>\n",
       "      <td>242247</td>\n",
       "      <td>20O0017851</td>\n",
       "      <td>True</td>\n",
       "      <td>Singapore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242248</th>\n",
       "      <td>242248</td>\n",
       "      <td>20O0017860</td>\n",
       "      <td>0.089723</td>\n",
       "      <td>0.910277</td>\n",
       "      <td>242248-20O0017860</td>\n",
       "      <td>242248</td>\n",
       "      <td>20O0017860</td>\n",
       "      <td>True</td>\n",
       "      <td>Singapore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242249</th>\n",
       "      <td>242249</td>\n",
       "      <td>20O0017861</td>\n",
       "      <td>0.016748</td>\n",
       "      <td>0.983252</td>\n",
       "      <td>242249-20O0017861</td>\n",
       "      <td>242249</td>\n",
       "      <td>20O0017861</td>\n",
       "      <td>True</td>\n",
       "      <td>Singapore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242250</th>\n",
       "      <td>242250</td>\n",
       "      <td>20O0017862</td>\n",
       "      <td>0.024889</td>\n",
       "      <td>0.975111</td>\n",
       "      <td>242250-20O0017862</td>\n",
       "      <td>242250</td>\n",
       "      <td>20O0017862</td>\n",
       "      <td>True</td>\n",
       "      <td>Singapore</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>242251 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index_x Serial ID_x     False      True          KeyIndSer index_y  \\\n",
       "0            0    Y0302794  0.996717  0.003283         0-Y0302794       0   \n",
       "1            1    Y1108983  0.945893  0.054107         1-Y1108983       1   \n",
       "2            2    Y0403242  0.996717  0.003283         2-Y0403242       2   \n",
       "3            3    Y1108995  0.945893  0.054107         3-Y1108995       3   \n",
       "4            4      AU4072  0.416496  0.583504           4-AU4072       4   \n",
       "...        ...         ...       ...       ...                ...     ...   \n",
       "242246  242246  20O0017852  0.095908  0.904092  242246-20O0017852  242246   \n",
       "242247  242247  20O0017851  0.164426  0.835574  242247-20O0017851  242247   \n",
       "242248  242248  20O0017860  0.089723  0.910277  242248-20O0017860  242248   \n",
       "242249  242249  20O0017861  0.016748  0.983252  242249-20O0017861  242249   \n",
       "242250  242250  20O0017862  0.024889  0.975111  242250-20O0017862  242250   \n",
       "\n",
       "       Serial ID_y  Churn    Sales Organisation  \n",
       "0         Y0302794  False             NP-France  \n",
       "1         Y1108983  False             NP-France  \n",
       "2         Y0403242  False             NP-France  \n",
       "3         Y1108995  False             NP-France  \n",
       "4           AU4072  False  Nestle Australia Ltd  \n",
       "...            ...    ...                   ...  \n",
       "242246  20O0017852   True             Singapore  \n",
       "242247  20O0017851   True             Singapore  \n",
       "242248  20O0017860   True             Singapore  \n",
       "242249  20O0017861   True             Singapore  \n",
       "242250  20O0017862   True             Singapore  \n",
       "\n",
       "[242251 rows x 9 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.to_csv(r'C:\\Users\\msalomo\\predictions-Churn-RandomForest2.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'#months of data', 'Depreciation Start',\n",
    "       'Industry (EC ID)_0614 InStore Food Service',\n",
    "       'End Date in Local Time Zone_x', \n",
    "       'G/R/M TB_MTB (Market)', 'Position_#', 'Position_LOAN',\n",
    "       'Incident Category_New Customer / Installation Point',\n",
    "       'User Status_Installed', 'Model Group_Other',\n",
    "       'User Status_To be removed', 'Service Category_Installation.',\n",
    "       'Last_visit_diff_months', 'Model Vendor_SAI Vending',\n",
    "       'Trading Partner_Direct', 'End Date in Local Time Zone_y',\n",
    "       'Industry (EC ID)_0614 Convenience OOH',\n",
    "       'System Brands_Nescafé Branded'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest generally outperforms Decision Tree for accuracy, which is the case. \n",
    "I am focusing on the F1_macro score, and here Random Forest also outperforms decision tree for F1_macro."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
