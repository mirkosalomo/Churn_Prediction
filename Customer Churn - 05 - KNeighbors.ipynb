{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone proposal by Mirko Salomon \n",
    "\n",
    "# BEVERAGE MACHINE CHURN PREDICTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ## [1) Introduction and preparation](#Introduction) \n",
    "\n",
    "    *   \n",
    "        #### Data Load\n",
    "        \n",
    "        #### Hyperparameters\n",
    "\n",
    "    \n",
    "* ## [2) KNeighbors model](#Knn)\n",
    "    \n",
    "    *   \n",
    "        #### Train the model\n",
    "        \n",
    "        #### Test data with best parameters \n",
    "        \n",
    "        #### Confusion Matrix\n",
    "        \n",
    "        #### Prediction of churn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Introduction and preparation<a class=\"anchor\" id=\"Introduction\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regression based on k-nearest neighbors.\n",
    "\n",
    "The KNN algorithm assumes that similar things exist in close proximity. Source : towardsdatascience\n",
    "\n",
    "K-NN is a type of instance-based learning, or lazy learning, where the function is only approximated locally and all computation is deferred until function evaluation. Since this algorithm relies on distance for classification, normalizing the training data can improve its accuracy dramatically. Source: Wikipedia\n",
    "\n",
    "Based on the flowchart from Scikit Learn I should try Kneighbors model. https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html\n",
    "\n",
    "This model is easy to understand and interpret, it does not requires a lot of training and is fast to implement\n",
    "Since the algorithm requires no training before making predictions, new data can be added seamlessly.\n",
    "The two main parameters to tune are the number of neighbors and the distance (e.g. Euclidean or Manhattan etc.)\n",
    "\n",
    "It might not have the best performance with large number of dimensions and with categorical features, it becomes difficult for the algorithm to calculate distance in each dimension.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pickle\n",
    "\n",
    "import xlrd\n",
    "\n",
    "import datetime as dt\n",
    "from datetime import datetime\n",
    "\n",
    "import collections\n",
    "from collections import Counter\n",
    "\n",
    "# Import seaborn\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#libraries\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "from sklearn import metrics \n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pickle file\n",
    "with open('BM_noTickets_preprocess.p', 'rb') as file:\n",
    "    BM_noTickets_preprocess = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pickle file\n",
    "with open('X.p', 'rb') as file:\n",
    "    X = pickle.load(file)\n",
    "\n",
    "# Load the pickle file\n",
    "with open('y.p', 'rb') as file:\n",
    "    y = pickle.load(file)\n",
    "\n",
    "# Load the pickle file\n",
    "with open('X_tr.p', 'rb') as file:\n",
    "    X_tr = pickle.load(file)\n",
    "\n",
    "# Load the pickle file\n",
    "with open('y_tr.p', 'rb') as file:\n",
    "    y_tr = pickle.load(file)\n",
    "\n",
    "# Load the pickle file\n",
    "with open('X_val.p', 'rb') as file:\n",
    "    X_val = pickle.load(file)\n",
    "\n",
    "# Load the pickle file\n",
    "with open('y_val.p', 'rb') as file:\n",
    "    y_val = pickle.load(file)\n",
    "\n",
    "# Load the pickle file\n",
    "with open('X_te.p', 'rb') as file:\n",
    "    X_te = pickle.load(file)\n",
    "\n",
    "# Load the pickle file\n",
    "with open('y_te.p', 'rb') as file:\n",
    "    y_te = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TA Contract Installation Date</th>\n",
       "      <th>Depreciation Start</th>\n",
       "      <th>TA Contract Start Date</th>\n",
       "      <th>TA Contract End Date</th>\n",
       "      <th>#months of data</th>\n",
       "      <th>Churn</th>\n",
       "      <th>Service Category_Installation</th>\n",
       "      <th>Service Category_Installation.</th>\n",
       "      <th>Service Category_Removal</th>\n",
       "      <th>Service Category_Removal.</th>\n",
       "      <th>...</th>\n",
       "      <th>IP Ownership_Exclusive</th>\n",
       "      <th>IP Ownership_Non-Proprietary</th>\n",
       "      <th>IP Ownership_Propr. Comp.</th>\n",
       "      <th>IP Ownership_Proprietary</th>\n",
       "      <th>Trading Partner_%23-Unknown</th>\n",
       "      <th>Trading Partner_Direct</th>\n",
       "      <th>Trading Partner_EVS</th>\n",
       "      <th>G/R/M TB_GTB (Global)</th>\n",
       "      <th>G/R/M TB_MTB (Market)</th>\n",
       "      <th>G/R/M TB_RTB (Regional)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>990.0</td>\n",
       "      <td>457.0</td>\n",
       "      <td>952.0</td>\n",
       "      <td>-79.931807</td>\n",
       "      <td>9.955030</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>990.0</td>\n",
       "      <td>1158.0</td>\n",
       "      <td>952.0</td>\n",
       "      <td>-79.931807</td>\n",
       "      <td>7.950882</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>990.0</td>\n",
       "      <td>1188.0</td>\n",
       "      <td>952.0</td>\n",
       "      <td>-79.931807</td>\n",
       "      <td>7.950882</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>990.0</td>\n",
       "      <td>1188.0</td>\n",
       "      <td>952.0</td>\n",
       "      <td>-79.931807</td>\n",
       "      <td>7.950882</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>990.0</td>\n",
       "      <td>1188.0</td>\n",
       "      <td>952.0</td>\n",
       "      <td>-79.931807</td>\n",
       "      <td>7.950882</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1059 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   TA Contract Installation Date  Depreciation Start  TA Contract Start Date  \\\n",
       "0                          990.0               457.0                   952.0   \n",
       "1                          990.0              1158.0                   952.0   \n",
       "2                          990.0              1188.0                   952.0   \n",
       "3                          990.0              1188.0                   952.0   \n",
       "4                          990.0              1188.0                   952.0   \n",
       "\n",
       "   TA Contract End Date  #months of data  Churn  \\\n",
       "0            -79.931807         9.955030  False   \n",
       "1            -79.931807         7.950882  False   \n",
       "2            -79.931807         7.950882  False   \n",
       "3            -79.931807         7.950882  False   \n",
       "4            -79.931807         7.950882  False   \n",
       "\n",
       "   Service Category_Installation  Service Category_Installation.  \\\n",
       "0                            0.0                             0.0   \n",
       "1                            0.0                             0.0   \n",
       "2                            0.0                             0.0   \n",
       "3                            0.0                             0.0   \n",
       "4                            0.0                             0.0   \n",
       "\n",
       "   Service Category_Removal  Service Category_Removal.  ...  \\\n",
       "0                       0.0                        0.0  ...   \n",
       "1                       0.0                        0.0  ...   \n",
       "2                       0.0                        0.0  ...   \n",
       "3                       0.0                        0.0  ...   \n",
       "4                       0.0                        0.0  ...   \n",
       "\n",
       "   IP Ownership_Exclusive  IP Ownership_Non-Proprietary  \\\n",
       "0                       0                             0   \n",
       "1                       0                             0   \n",
       "2                       0                             0   \n",
       "3                       0                             0   \n",
       "4                       0                             0   \n",
       "\n",
       "   IP Ownership_Propr. Comp.  IP Ownership_Proprietary  \\\n",
       "0                          1                         0   \n",
       "1                          1                         0   \n",
       "2                          1                         0   \n",
       "3                          1                         0   \n",
       "4                          1                         0   \n",
       "\n",
       "   Trading Partner_%23-Unknown  Trading Partner_Direct  Trading Partner_EVS  \\\n",
       "0                            0                       0                    1   \n",
       "1                            0                       0                    1   \n",
       "2                            0                       0                    1   \n",
       "3                            0                       0                    1   \n",
       "4                            0                       0                    1   \n",
       "\n",
       "   G/R/M TB_GTB (Global)  G/R/M TB_MTB (Market)  G/R/M TB_RTB (Regional)  \n",
       "0                      1                      0                        0  \n",
       "1                      1                      0                        0  \n",
       "2                      1                      0                        0  \n",
       "3                      1                      0                        0  \n",
       "4                      1                      0                        0  \n",
       "\n",
       "[5 rows x 1059 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BM_noTickets_preprocess.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#class sklearn.neighbors.KNeighborsClassifier(n_neighbors=5, *, weights='uniform', algorithm='auto', leaf_size=30, p=2, metric='minkowski', metric_params=None, n_jobs=None, **kwargs)\n",
    "\n",
    "---\n",
    "\n",
    "Use several number of neighbors to use.\n",
    "k_values = np.arange(1, 21)\n",
    "\n",
    "---\n",
    "\n",
    "‘uniform’ : uniform weights. All points in each neighborhood are weighted equally.\n",
    "\n",
    "‘distance’ : weight points by the inverse of their distance. in this case, closer neighbors of a query point will have a greater influence than neighbors which are further away.\n",
    "\n",
    "weights_functions = ['uniform', 'distance']\n",
    "\n",
    "---\n",
    "\n",
    "When p = 1, this is equivalent to using manhattan_distance (l1), and euclidean_distance (l2) for p = 2\n",
    "\n",
    "distance_types = [1, 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Kneighbors model<a class=\"anchor\" id=\"Knn\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a set of reasonable values\n",
    "k_values = np.arange(1, 21) # 1, 2, 3, .., 20\n",
    "weights_functions = ['uniform', 'distance']\n",
    "distance_types = [1, 2] #When p = 1, this is equivalent to using manhattan_distance (l1), and euclidean_distance (l2) for p = 2\n",
    "\n",
    "# Define a grid of values\n",
    "grid = ParameterGrid({\n",
    "    'knn__n_neighbors': k_values,\n",
    "    'knn__weights': weights_functions,\n",
    "    'knn__p': distance_types\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of combinations: 80\n",
      "{'knn__n_neighbors': 1, 'knn__p': 1, 'knn__weights': 'uniform'}\n",
      "{'knn__n_neighbors': 1, 'knn__p': 1, 'knn__weights': 'distance'}\n",
      "{'knn__n_neighbors': 1, 'knn__p': 2, 'knn__weights': 'uniform'}\n",
      "{'knn__n_neighbors': 1, 'knn__p': 2, 'knn__weights': 'distance'}\n",
      "{'knn__n_neighbors': 2, 'knn__p': 1, 'knn__weights': 'uniform'}\n",
      "{'knn__n_neighbors': 2, 'knn__p': 1, 'knn__weights': 'distance'}\n",
      "{'knn__n_neighbors': 2, 'knn__p': 2, 'knn__weights': 'uniform'}\n",
      "{'knn__n_neighbors': 2, 'knn__p': 2, 'knn__weights': 'distance'}\n",
      "{'knn__n_neighbors': 3, 'knn__p': 1, 'knn__weights': 'uniform'}\n",
      "{'knn__n_neighbors': 3, 'knn__p': 1, 'knn__weights': 'distance'}\n",
      "{'knn__n_neighbors': 3, 'knn__p': 2, 'knn__weights': 'uniform'}\n",
      "{'knn__n_neighbors': 3, 'knn__p': 2, 'knn__weights': 'distance'}\n",
      "{'knn__n_neighbors': 4, 'knn__p': 1, 'knn__weights': 'uniform'}\n",
      "{'knn__n_neighbors': 4, 'knn__p': 1, 'knn__weights': 'distance'}\n",
      "{'knn__n_neighbors': 4, 'knn__p': 2, 'knn__weights': 'uniform'}\n",
      "{'knn__n_neighbors': 4, 'knn__p': 2, 'knn__weights': 'distance'}\n",
      "{'knn__n_neighbors': 5, 'knn__p': 1, 'knn__weights': 'uniform'}\n",
      "{'knn__n_neighbors': 5, 'knn__p': 1, 'knn__weights': 'distance'}\n",
      "{'knn__n_neighbors': 5, 'knn__p': 2, 'knn__weights': 'uniform'}\n",
      "{'knn__n_neighbors': 5, 'knn__p': 2, 'knn__weights': 'distance'}\n",
      "{'knn__n_neighbors': 6, 'knn__p': 1, 'knn__weights': 'uniform'}\n",
      "{'knn__n_neighbors': 6, 'knn__p': 1, 'knn__weights': 'distance'}\n",
      "{'knn__n_neighbors': 6, 'knn__p': 2, 'knn__weights': 'uniform'}\n",
      "{'knn__n_neighbors': 6, 'knn__p': 2, 'knn__weights': 'distance'}\n",
      "{'knn__n_neighbors': 7, 'knn__p': 1, 'knn__weights': 'uniform'}\n",
      "{'knn__n_neighbors': 7, 'knn__p': 1, 'knn__weights': 'distance'}\n",
      "{'knn__n_neighbors': 7, 'knn__p': 2, 'knn__weights': 'uniform'}\n",
      "{'knn__n_neighbors': 7, 'knn__p': 2, 'knn__weights': 'distance'}\n",
      "{'knn__n_neighbors': 8, 'knn__p': 1, 'knn__weights': 'uniform'}\n",
      "{'knn__n_neighbors': 8, 'knn__p': 1, 'knn__weights': 'distance'}\n",
      "{'knn__n_neighbors': 8, 'knn__p': 2, 'knn__weights': 'uniform'}\n",
      "{'knn__n_neighbors': 8, 'knn__p': 2, 'knn__weights': 'distance'}\n",
      "{'knn__n_neighbors': 9, 'knn__p': 1, 'knn__weights': 'uniform'}\n",
      "{'knn__n_neighbors': 9, 'knn__p': 1, 'knn__weights': 'distance'}\n",
      "{'knn__n_neighbors': 9, 'knn__p': 2, 'knn__weights': 'uniform'}\n",
      "{'knn__n_neighbors': 9, 'knn__p': 2, 'knn__weights': 'distance'}\n",
      "{'knn__n_neighbors': 10, 'knn__p': 1, 'knn__weights': 'uniform'}\n",
      "{'knn__n_neighbors': 10, 'knn__p': 1, 'knn__weights': 'distance'}\n",
      "{'knn__n_neighbors': 10, 'knn__p': 2, 'knn__weights': 'uniform'}\n",
      "{'knn__n_neighbors': 10, 'knn__p': 2, 'knn__weights': 'distance'}\n",
      "{'knn__n_neighbors': 11, 'knn__p': 1, 'knn__weights': 'uniform'}\n",
      "{'knn__n_neighbors': 11, 'knn__p': 1, 'knn__weights': 'distance'}\n",
      "{'knn__n_neighbors': 11, 'knn__p': 2, 'knn__weights': 'uniform'}\n",
      "{'knn__n_neighbors': 11, 'knn__p': 2, 'knn__weights': 'distance'}\n",
      "{'knn__n_neighbors': 12, 'knn__p': 1, 'knn__weights': 'uniform'}\n",
      "{'knn__n_neighbors': 12, 'knn__p': 1, 'knn__weights': 'distance'}\n",
      "{'knn__n_neighbors': 12, 'knn__p': 2, 'knn__weights': 'uniform'}\n",
      "{'knn__n_neighbors': 12, 'knn__p': 2, 'knn__weights': 'distance'}\n",
      "{'knn__n_neighbors': 13, 'knn__p': 1, 'knn__weights': 'uniform'}\n",
      "{'knn__n_neighbors': 13, 'knn__p': 1, 'knn__weights': 'distance'}\n",
      "{'knn__n_neighbors': 13, 'knn__p': 2, 'knn__weights': 'uniform'}\n",
      "{'knn__n_neighbors': 13, 'knn__p': 2, 'knn__weights': 'distance'}\n",
      "{'knn__n_neighbors': 14, 'knn__p': 1, 'knn__weights': 'uniform'}\n",
      "{'knn__n_neighbors': 14, 'knn__p': 1, 'knn__weights': 'distance'}\n",
      "{'knn__n_neighbors': 14, 'knn__p': 2, 'knn__weights': 'uniform'}\n",
      "{'knn__n_neighbors': 14, 'knn__p': 2, 'knn__weights': 'distance'}\n",
      "{'knn__n_neighbors': 15, 'knn__p': 1, 'knn__weights': 'uniform'}\n",
      "{'knn__n_neighbors': 15, 'knn__p': 1, 'knn__weights': 'distance'}\n",
      "{'knn__n_neighbors': 15, 'knn__p': 2, 'knn__weights': 'uniform'}\n",
      "{'knn__n_neighbors': 15, 'knn__p': 2, 'knn__weights': 'distance'}\n",
      "{'knn__n_neighbors': 16, 'knn__p': 1, 'knn__weights': 'uniform'}\n",
      "{'knn__n_neighbors': 16, 'knn__p': 1, 'knn__weights': 'distance'}\n",
      "{'knn__n_neighbors': 16, 'knn__p': 2, 'knn__weights': 'uniform'}\n",
      "{'knn__n_neighbors': 16, 'knn__p': 2, 'knn__weights': 'distance'}\n",
      "{'knn__n_neighbors': 17, 'knn__p': 1, 'knn__weights': 'uniform'}\n",
      "{'knn__n_neighbors': 17, 'knn__p': 1, 'knn__weights': 'distance'}\n",
      "{'knn__n_neighbors': 17, 'knn__p': 2, 'knn__weights': 'uniform'}\n",
      "{'knn__n_neighbors': 17, 'knn__p': 2, 'knn__weights': 'distance'}\n",
      "{'knn__n_neighbors': 18, 'knn__p': 1, 'knn__weights': 'uniform'}\n",
      "{'knn__n_neighbors': 18, 'knn__p': 1, 'knn__weights': 'distance'}\n",
      "{'knn__n_neighbors': 18, 'knn__p': 2, 'knn__weights': 'uniform'}\n",
      "{'knn__n_neighbors': 18, 'knn__p': 2, 'knn__weights': 'distance'}\n",
      "{'knn__n_neighbors': 19, 'knn__p': 1, 'knn__weights': 'uniform'}\n",
      "{'knn__n_neighbors': 19, 'knn__p': 1, 'knn__weights': 'distance'}\n",
      "{'knn__n_neighbors': 19, 'knn__p': 2, 'knn__weights': 'uniform'}\n",
      "{'knn__n_neighbors': 19, 'knn__p': 2, 'knn__weights': 'distance'}\n",
      "{'knn__n_neighbors': 20, 'knn__p': 1, 'knn__weights': 'uniform'}\n",
      "{'knn__n_neighbors': 20, 'knn__p': 1, 'knn__weights': 'distance'}\n",
      "{'knn__n_neighbors': 20, 'knn__p': 2, 'knn__weights': 'uniform'}\n",
      "{'knn__n_neighbors': 20, 'knn__p': 2, 'knn__weights': 'distance'}\n"
     ]
    }
   ],
   "source": [
    "# Print the number of combinations\n",
    "print('Number of combinations:', len(grid))\n",
    "\n",
    "# Iterate through each combination of parameters\n",
    "for params_dict in grid:\n",
    "    print(params_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create k-NN classifier\n",
    "pipe = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('knn', KNeighborsClassifier())\n",
    "])\n",
    "\n",
    "# Save accuracy on test set\n",
    "test_scores = []\n",
    "\n",
    "for params_dict in grid:\n",
    "    # Set parameters\n",
    "    pipe.set_params(**params_dict)\n",
    "\n",
    "    # Fit a k-NN classifier\n",
    "    pipe.fit(X_tr, y_tr)\n",
    "\n",
    "    # Save accuracy on validation set\n",
    "    params_dict['accuracy'] = pipe.score(X_val, y_val)\n",
    "    # Save f1 score on validation set\n",
    "    # predict test instances\n",
    "    y_pred = pipe.predict(X_val)\n",
    "    params_dict['f1_macro'] = metrics.f1_score(y_val, y_pred, average='macro')\n",
    "    \n",
    "    # Save result\n",
    "    test_scores.append(params_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create DataFrame with test scores\n",
    "scores_df = pd.DataFrame(test_scores)\n",
    "\n",
    "# Top five scores\n",
    "scores_df.sort_values(by='f1_macro', ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test data with best parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_dict = {'knn__n_neighbors': 2, \n",
    " 'knn__p': 1, \n",
    " 'knn__weights': 'uniform'}\n",
    "\n",
    "# Create pipeline, kNN classifier\n",
    "pipe = Pipeline([\n",
    "    #('oversample', SmoteSample_model),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('knn', KNeighborsClassifier())\n",
    "    ]\n",
    ")\n",
    "   \n",
    "# Save accuracy on test set\n",
    "test_scores = []\n",
    "\n",
    "# Set parameters\n",
    "pipe.set_params(**params_dict)\n",
    "\n",
    "# Fit a k-NN classifier\n",
    "pipe.fit(X_tr, y_tr)\n",
    "\n",
    "# Save accuracy on validation set\n",
    "params_dict['accuracy'] = pipe.score(X_te, y_te)\n",
    "# Save f1 score on validation set\n",
    "# predict test instances\n",
    "y_pred = pipe.predict(X_te)\n",
    "params_dict['f1_macro'] = metrics.f1_score(y_te, y_pred, average='macro')\n",
    "    \n",
    "# Save result\n",
    "test_scores.append(params_dict)\n",
    "    \n",
    "# Create DataFrame with test scores\n",
    "scores_df = pd.DataFrame(test_scores)\n",
    "\n",
    "# Top five scores\n",
    "scores_df.sort_values(by='f1_macro', ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have an F1 Macro score of 82% and an accuracy of 93% with the test data. Which is a bit better than the validation data results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# F1_score\n",
    "knn_F1Macro = params_dict['f1_macro']\n",
    "\n",
    "# Accuracy\n",
    "knn_accuracy = params_dict['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the npz file for results\n",
    "with np.load('Results.npz', allow_pickle=False) as npz_file:\n",
    "    F1Score = npz_file['test_F1Score']\n",
    "    accuracy = npz_file['test_accuracy']\n",
    "    models = npz_file['models']\n",
    "    \n",
    "# Fill the calculated result value\n",
    "F1Score[2] = knn_F1Macro\n",
    "accuracy[2] = knn_accuracy\n",
    "\n",
    "print('F1_Results:', F1Score)\n",
    "print('Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify the Numpy array\n",
    "#Model = models #unchanged\n",
    "Result = F1Score\n",
    "Accuracy = accuracy\n",
    "\n",
    "# Store the changes in the results npz file\n",
    "np.savez('Results.npz', models = models, test_F1Score = Result,  test_accuracy = Accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the refreshed results\n",
    "# Load the npz file for results\n",
    "with np.load('Results.npz', allow_pickle=False) as npz_file:\n",
    "    # It's a dictionary-like object    \n",
    "    print(list(npz_file.keys()))\n",
    "    # Load the arrays\n",
    "    print('Models:', npz_file['models'])\n",
    "    print('F1_Results:', npz_file['test_F1Score'])\n",
    "    print('Accuracy:', npz_file['test_accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classification reports and confusion matrices are commonly used for reporting the performance of classifiers when working with imbalanced datasets.\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(metrics.confusion_matrix(y_te, y_pred))\n",
    "\n",
    "# Print the precision and recall, among other metrics\n",
    "print(metrics.classification_report(y_te, y_pred, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Classification reports and confusion matrices are commonly used for reporting the performance of classifiers when working with imbalanced datasets.\n",
    "ConfMat_df = pd.DataFrame(metrics.confusion_matrix(y_te, y_pred).T, columns=['False Condition', 'True Condition'],index=['Predicted False', 'Predicted True'])\n",
    "ConfMat_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a good F1 Score for the False Condition but not as good for the True Condition. This explains why even if we have a good accuracy the F1 Macro Score is lower."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the Dataframe into a pickle file\n",
    "with open('KNeighbors_ConfMat_df.p', 'wb') as file:\n",
    "    pickle.dump(ConfMat_df, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction of churn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's predict the churn for each Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need the one in the same format, so with removed Sales Org\n",
    "# Load the pickle file\n",
    "with open('BM_noTicketsWOSO.p', 'rb') as file:\n",
    "    BM_noTicketsWOSO = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = ['False', 'True']\n",
    "No=BM_noTicketsWOSO['Serial ID']\n",
    "predictions = pipe.predict_proba(X)\n",
    "# With two column indices, values same  \n",
    "# as dictionary keys \n",
    "df2 = pd.DataFrame(predictions, index=No ,columns = name) \n",
    "df2.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
